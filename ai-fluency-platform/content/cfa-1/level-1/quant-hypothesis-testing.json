{
  "meta": {
    "title": "QM.8: Hypothesis Testing",
    "description": "Conduct and interpret hypothesis tests including z-tests, t-tests, and chi-square tests. Understand p-values, Type I/Type II errors, and one-tailed vs two-tailed tests.",
    "level": "level-1",
    "slug": "quant-hypothesis-testing",
    "order": 8,
    "isCheckpoint": false,
    "isIndex": false,
    "cfaTopic": "Quantitative Methods"
  },
  "blocks": [
    {
      "type": "predictPrompt",
      "prompt": "A fund manager claims their fund beats the market average return of 10%. Over the past 36 months, the fund averaged 12% with a standard deviation of 15%. Is this enough evidence to support the manager's claim, or could it be due to luck?"
    },
    {
      "type": "markdown",
      "content": "## Hypothesis Testing Framework\n\nHypothesis testing is a formal process for making statistical decisions about population parameters.\n\n### Step-by-Step Process\n\n1. **State the hypotheses**: Define $H_0$ (null) and $H_a$ (alternative)\n2. **Select the significance level** ($\\alpha$): Common choices are 0.01, 0.05, or 0.10\n3. **Choose the test statistic**: Based on the parameter and data characteristics\n4. **State the decision rule**: Determine critical value(s) or use p-value approach\n5. **Calculate the test statistic**: From sample data\n6. **Make a decision**: Reject or fail to reject $H_0$\n\n### Null and Alternative Hypotheses\n\nThe **null hypothesis** ($H_0$) is the \"status quo\" or \"no effect\" claim. It always contains an equality ($=$, $\\leq$, or $\\geq$). The **alternative hypothesis** ($H_a$) is what you are trying to provide evidence for.\n\n| Test Type | $H_0$ | $H_a$ | Rejection Region |\n|---|---|---|---|\n| Two-tailed | $\\mu = \\mu_0$ | $\\mu \\neq \\mu_0$ | Both tails |\n| Right-tailed | $\\mu \\leq \\mu_0$ | $\\mu > \\mu_0$ | Right tail only |\n| Left-tailed | $\\mu \\geq \\mu_0$ | $\\mu < \\mu_0$ | Left tail only |\n\nThe significance level $\\alpha$ is the probability of rejecting a true null hypothesis."
    },
    {
      "type": "calibrationCheck",
      "question": "An analyst tests H\u2080: \u03bc = 5% vs H\u2090: \u03bc \u2260 5% at \u03b1 = 0.05. The test statistic is 1.80 and the critical values are \u00b11.96. What is the conclusion?",
      "answer": "Fail to reject H\u2080. The test statistic (1.80) falls within the acceptance region (-1.96 to +1.96). There is insufficient evidence at the 5% significance level to conclude that \u03bc differs from 5%. Note: we say 'fail to reject' rather than 'accept' \u2014 we have not proven H\u2080 is true, only that we lack sufficient evidence to reject it."
    },
    {
      "type": "markdown",
      "content": "## Type I and Type II Errors\n\n| | $H_0$ is True | $H_0$ is False |\n|---|---|---|\n| **Reject $H_0$** | Type I error ($\\alpha$) | Correct decision |\n| **Fail to reject $H_0$** | Correct decision | Type II error ($\\beta$) |\n\n- **Type I error**: Rejecting a true null hypothesis (\"false positive\"). Probability = $\\alpha$.\n- **Type II error**: Failing to reject a false null hypothesis (\"false negative\"). Probability = $\\beta$.\n- **Power**: Probability of correctly rejecting a false $H_0$. Power = $1 - \\beta$.\n\n### The Tradeoff\n\nFor a given sample size, decreasing $\\alpha$ (making it harder to reject $H_0$) **increases** $\\beta$ (making it more likely to miss a true effect). The only way to reduce both errors simultaneously is to **increase the sample size**.\n\n### p-Values\n\nThe **p-value** is the smallest significance level at which $H_0$ would be rejected. Equivalently, it is the probability of observing a test statistic as extreme as (or more extreme than) the one calculated, assuming $H_0$ is true.\n\n**Decision rule**: Reject $H_0$ if p-value $< \\alpha$.\n\nA smaller p-value provides stronger evidence against $H_0$."
    },
    {
      "type": "markdown",
      "content": "## Common Test Statistics\n\n### z-Test for Population Mean (\u03c3 known)\n\n$$z = \\frac{\\bar{X} - \\mu_0}{\\sigma / \\sqrt{n}}$$\n\n### t-Test for Population Mean (\u03c3 unknown)\n\n$$t = \\frac{\\bar{X} - \\mu_0}{s / \\sqrt{n}} \\quad (df = n-1)$$\n\n### Chi-Square Test for Population Variance\n\n$$\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2} \\quad (df = n-1)$$\n\nThe chi-square distribution is always positive and right-skewed.\n\n### Example: Testing a Manager's Claim\n\nA fund manager claims returns exceed 10%. Over 36 months: $\\bar{X} = 12\\%$, $s = 15\\%$.\n\n$H_0: \\mu \\leq 10\\%$ vs $H_a: \\mu > 10\\%$ (one-tailed test)\n\n$$t = \\frac{12\\% - 10\\%}{15\\% / \\sqrt{36}} = \\frac{2\\%}{2.5\\%} = 0.80$$\n\nCritical value at $\\alpha = 0.05$ (one-tailed, 35 df): $t_{0.05} \\approx 1.69$\n\nSince $0.80 < 1.69$, we **fail to reject** $H_0$. The outperformance is not statistically significant \u2014 it could easily be due to chance given the high volatility.\n\n### Statistical vs Economic Significance\n\nA result can be statistically significant but economically meaningless (e.g., a fund beats the benchmark by 0.01% with a huge sample). Conversely, an economically meaningful result may not be statistically significant (as in our example above). Always consider both."
    },
    {
      "type": "tryItYourself",
      "title": "A portfolio's risk manager claims the portfolio's annual variance is no more than 400 (i.e., \u03c3\u00b2 \u2264 400, implying \u03c3 \u2264 20%). A sample of 25 annual returns has a sample variance of 625. Test at the 5% significance level. (Chi-square critical value with 24 df at \u03b1 = 0.05, one-tailed right: 36.415)",
      "solution": "**Hypotheses:**\n\n$H_0: \\sigma^2 \\leq 400$ vs $H_a: \\sigma^2 > 400$ (one-tailed right)\n\n**Test statistic:**\n\n$$\\chi^2 = \\frac{(n-1)s^2}{\\sigma_0^2} = \\frac{(25-1)(625)}{400} = \\frac{24 \\times 625}{400} = \\frac{15{,}000}{400} = 37.5$$\n\n**Decision rule:** Reject $H_0$ if $\\chi^2 > 36.415$\n\n**Conclusion:** Since $37.5 > 36.415$, we **reject** $H_0$ at the 5% significance level.\n\nThere is sufficient evidence that the portfolio's variance exceeds 400 (standard deviation exceeds 20%). The sample variance of 625 (standard deviation of 25%) is significantly higher than the claimed maximum.\n\nThe risk manager's claim does not hold \u2014 the portfolio is riskier than stated."
    },
    {
      "type": "practiceSet",
      "title": "Hypothesis Testing Practice Problems",
      "problems": [
        {
          "id": "qm8-1",
          "question": "In hypothesis testing, a Type I error occurs when:",
          "options": [
            "A) The null hypothesis is true and is rejected",
            "B) The null hypothesis is false and is not rejected",
            "C) The null hypothesis is false and is rejected"
          ],
          "correctAnswer": "A",
          "explanation": "A Type I error is a 'false positive' \u2014 rejecting H\u2080 when it is actually true. The probability of a Type I error equals \u03b1. Option B describes a Type II error (false negative). Option C is the correct decision (correctly rejecting a false H\u2080), with probability equal to the power of the test (1 - \u03b2).",
          "difficulty": "basic",
          "cfaTopic": "Quantitative Methods",
          "learningOutcome": "Distinguish between Type I and Type II errors"
        },
        {
          "id": "qm8-2",
          "question": "A two-tailed test at \u03b1 = 0.05 has critical z-values of \u00b11.96. A one-tailed test at the same \u03b1 has a critical z-value of 1.645. An analyst obtains a test statistic of 1.80. The result is:",
          "options": [
            "A) Significant under both tests",
            "B) Significant under the one-tailed test only",
            "C) Significant under the two-tailed test only"
          ],
          "correctAnswer": "B",
          "explanation": "For the one-tailed test: 1.80 > 1.645, so reject H\u2080. For the two-tailed test: 1.80 < 1.96, so fail to reject H\u2080. The one-tailed test is more powerful in one direction because it concentrates all \u03b1 in one tail. Option A is incorrect because 1.80 < 1.96. Option C reverses the results.",
          "difficulty": "intermediate",
          "cfaTopic": "Quantitative Methods",
          "learningOutcome": "Compare one-tailed and two-tailed hypothesis tests"
        },
        {
          "id": "qm8-3",
          "question": "An analyst tests H\u2080: \u03bc = 0 versus H\u2090: \u03bc \u2260 0 and obtains a p-value of 0.03. At a significance level of 5%, the analyst should:",
          "options": [
            "A) Reject the null hypothesis",
            "B) Fail to reject the null hypothesis",
            "C) Increase the sample size before deciding"
          ],
          "correctAnswer": "A",
          "explanation": "Since the p-value (0.03) is less than \u03b1 (0.05), reject H\u2080. The p-value represents the probability of observing results this extreme if H\u2080 were true \u2014 at 3%, this is unlikely enough to reject. Option B would be correct if p-value > \u03b1. Option C is not part of the decision framework \u2014 once data is collected and p-value computed, the decision follows directly.",
          "difficulty": "basic",
          "cfaTopic": "Quantitative Methods",
          "learningOutcome": "Make decisions using p-values"
        },
        {
          "id": "qm8-4",
          "question": "A sample of 64 observations has a mean of 15 and a population standard deviation of 8. To test H\u2080: \u03bc \u2264 12 vs H\u2090: \u03bc > 12 at \u03b1 = 0.01 (z-critical = 2.326), the test statistic and conclusion are closest to:",
          "options": [
            "A) z = 3.0; reject H\u2080",
            "B) z = 3.0; fail to reject H\u2080",
            "C) z = 0.375; fail to reject H\u2080"
          ],
          "correctAnswer": "A",
          "explanation": "z = (15 - 12) / (8/\u221a64) = 3/1 = 3.0. Since 3.0 > 2.326 (critical value), reject H\u2080 at the 1% level. There is strong evidence that \u03bc > 12. Option B correctly calculates z but reaches the wrong conclusion. Option C divides by \u03c3 instead of \u03c3/\u221an: 3/8 = 0.375.",
          "difficulty": "advanced",
          "cfaTopic": "Quantitative Methods",
          "learningOutcome": "Conduct a z-test for a population mean"
        }
      ]
    },
    {
      "type": "explainBack",
      "prompt": "Explain the relationship between significance level (\u03b1), Type I error, Type II error, and power. Why can't we just set \u03b1 to a very small number like 0.001 to minimize mistakes? Use a courtroom analogy if it helps."
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "Why do we say 'fail to reject H\u2080' rather than 'accept H\u2080'? What is the philosophical difference?",
        "A hedge fund shows 10 years of returns and claims statistical significance. What potential issues should you consider?",
        "How does the distinction between statistical and economic significance apply to evaluating investment strategies?"
      ]
    },
    {
      "type": "keyTakeaway",
      "content": "**Key Formulas and Relationships:**\n\n- z-test: $z = (\\bar{X} - \\mu_0) / (\\sigma / \\sqrt{n})$ \u2014 when \u03c3 is known\n- t-test: $t = (\\bar{X} - \\mu_0) / (s / \\sqrt{n})$ \u2014 when \u03c3 is unknown ($df = n-1$)\n- Chi-square: $\\chi^2 = (n-1)s^2 / \\sigma_0^2$ \u2014 test for variance ($df = n-1$)\n- Type I error (\u03b1): rejecting a true H\u2080; Type II error (\u03b2): not rejecting a false H\u2080\n- Power = $1 - \\beta$: probability of correctly rejecting a false H\u2080\n- Reject H\u2080 if p-value < \u03b1, or if test statistic exceeds critical value\n- Increasing $n$ reduces both Type I and Type II errors\n- Always distinguish statistical significance from economic significance"
    },
    {
      "type": "connectPrompt",
      "prompt": "The next module covers **Parametric and Non-Parametric Tests**, extending the hypothesis testing framework to tests of independence and situations where standard distribution assumptions may not hold. You will learn when parametric tests fail and what alternatives exist."
    }
  ]
}
