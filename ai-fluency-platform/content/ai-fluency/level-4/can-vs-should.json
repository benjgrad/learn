{
  "meta": {
    "title": "4.7 Can vs. Should: AI Decision Frameworks",
    "description": "Evaluate when AI is the right solution versus traditional algorithms, considering complexity, cost, and determinism tradeoffs.",
    "level": "level-4",
    "slug": "can-vs-should",
    "order": 0,
    "isCheckpoint": false,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "markdown",
      "content": "# 4.7 Can vs. Should: AI Decision Frameworks"
    },
    {
      "type": "predictPrompt",
      "prompt": "Your team proposes using an LLM to validate email addresses from user input. Another engineer suggests using a regular expression instead. Who is right, and why?"
    },
    {
      "type": "markdown",
      "content": "## The AI Tax\n\nEvery AI component you add to a system introduces what we can call the **AI tax** -- a set of costs that traditional software does not carry:\n\n- **Non-determinism**: The same input can produce different outputs across calls. This makes testing harder, debugging harder, and reproducibility harder.\n- **Latency**: Even the fastest model API adds hundreds of milliseconds. A regex runs in microseconds.\n- **Cost**: API calls cost money per token. A database query costs fractions of a cent.\n- **Complexity**: AI components require prompt engineering, output validation, fallback logic, and ongoing evaluation. A `switch` statement requires none of this.\n- **Opacity**: When a traditional algorithm fails, the bug is in the code. When an AI component fails, the cause might be the prompt, the model version, the input phrasing, or a training data artifact.\n\nThe AI tax is not a reason to avoid AI -- it is a reason to be deliberate about where you pay it. **Use AI when the value justifies the tax. Use traditional tools when they do not.**\n\n## The Decision Framework\n\nWhen a feature request lands on your desk, run it through this framework before reaching for a model:\n\n### Step 1: Is the Problem Well-Defined?\n\nIf the problem has a clear, exhaustive set of rules, AI is likely overkill:\n\n| Problem | Traditional Solution | AI Needed? |\n|---------|---------------------|------------|\n| Validate email format | Regex | No |\n| Calculate sales tax | Lookup table + arithmetic | No |\n| Sort search results by date | SQL `ORDER BY` | No |\n| Route support tickets by keyword | Rule engine with keyword matching | Maybe |\n| Classify support tickets by intent | LLM or fine-tuned classifier | Yes |\n\nThe dividing line is **ambiguity**. When rules can fully specify the behavior, use rules. When the problem requires understanding natural language, handling edge cases that resist enumeration, or making judgment calls, AI becomes valuable.\n\n### Step 2: What Are the Alternatives?\n\nBefore choosing an LLM, consider the full spectrum of tools:\n\n- **Regex and string matching**: Pattern detection, format validation, simple extraction\n- **Rule engines**: Business logic with complex conditions, decision trees, configurable workflows\n- **SQL and database queries**: Aggregation, filtering, joining, reporting\n- **Traditional ML**: Classification, regression, clustering with tabular data (random forests, gradient boosting)\n- **Embeddings + vector search**: Semantic similarity without generative AI\n- **LLMs**: Open-ended generation, complex reasoning, nuanced classification, multi-step tasks\n\nEach step up this ladder adds capability but also adds the AI tax. Use the simplest tool that solves the problem."
    },
    {
      "type": "calibrationCheck",
      "question": "A product manager asks you to build a feature that auto-tags blog posts with categories from a fixed list of 8 categories. Each category has 5-10 defining keywords. What approach would you recommend and why?",
      "answer": "Start with **keyword matching and a scoring function**. For each post, count occurrences of each category's keywords, weight them, and assign the top-scoring category. This is deterministic, free, fast, and easy to debug.\n\nIf keyword matching achieves 85%+ accuracy on a test set, ship it. If accuracy is below that threshold -- likely because posts use varied language that keywords miss -- then consider **embeddings plus a simple classifier** (compute embedding similarity between the post and representative examples for each category). Only escalate to an LLM if the classification requires understanding nuance, context, or ambiguity that simpler approaches cannot handle.\n\nThe key insight: start simple, measure, and escalate only when data proves the simpler approach is insufficient."
    },
    {
      "type": "markdown",
      "content": "### Step 3: What Does Failure Look Like?\n\nThe cost of AI failure varies enormously by context:\n\n- **Low-stakes**: Auto-suggesting email subject lines. A bad suggestion is ignored. AI is fine.\n- **Medium-stakes**: Summarizing meeting notes. A missed detail is annoying but recoverable. AI is fine with human review.\n- **High-stakes**: Calculating medication dosages. A wrong answer is dangerous. AI alone is not fine.\n\nFor high-stakes decisions, either use deterministic systems or place AI behind mandatory human review. The question is not \"can AI do this?\" but \"what happens when AI gets it wrong?\"\n\n### Step 4: What Is the Total Cost of Ownership?\n\nA full cost comparison includes:\n\n| Cost Factor | Traditional | AI-Powered |\n|------------|-------------|------------|\n| Development time | Moderate | Higher (prompt eng, evals) |\n| Runtime cost | Near zero | Per-request API cost |\n| Maintenance | Update rules manually | Monitor model drift, retune prompts |\n| Testing | Unit tests | Evals + unit tests + regression suites |\n| Debugging | Deterministic traces | Probabilistic, may not reproduce |\n| Vendor risk | None (your code) | Model deprecation, API changes, price hikes |\n\n## Common Anti-Patterns\n\n**\"AI for validation\"**: Using an LLM to validate data that has a formal specification (email, phone numbers, dates). A regex or parser is faster, cheaper, and correct by construction.\n\n**\"AI for transformation\"**: Using an LLM to convert between well-defined formats (CSV to JSON, date format conversion). A few lines of code handle this deterministically.\n\n**\"AI for lookup\"**: Sending a query to an LLM when a database query or API call returns the exact answer. The model might hallucinate; the database will not.\n\n**\"AI for everything\"**: Defaulting to AI for every feature because it is exciting or because the team has AI expertise. This leads to unnecessary complexity, cost, and fragility."
    },
    {
      "type": "tryItYourself",
      "title": "Evaluate these 5 feature requests. For each one, decide whether AI is the right approach, recommend a specific technology, and justify your decision.",
      "solution": "**1. Detect duplicate customer accounts based on name and email variations.**\nRecommendation: **Fuzzy string matching** (Levenshtein distance, Jaro-Winkler). Deterministic, fast, and well-understood. AI is overkill for string similarity.\n\n**2. Generate personalized product descriptions from a structured product database.**\nRecommendation: **LLM**. This requires natural language generation from structured data, handling tone and style. Templates could work for simple cases, but personalization and variety require a generative model.\n\n**3. Flag potentially fraudulent transactions in real-time.**\nRecommendation: **Traditional ML** (gradient-boosted trees or random forest). Tabular data with known features (amount, location, time, merchant category) is the sweet spot for traditional ML. Lower latency and more explainable than an LLM.\n\n**4. Convert user-uploaded spreadsheets into a normalized database schema.**\nRecommendation: **Hybrid**. Use deterministic code for well-structured spreadsheets with clear headers. Use an LLM only for the ambiguous cases -- messy headers, inconsistent formats, merged cells -- where human-like judgment is needed to infer intent.\n\n**5. Automatically respond to customer reviews with personalized thank-you messages.**\nRecommendation: **LLM with guardrails**. The task requires understanding sentiment, referencing specific points from the review, and generating natural language. But add a human review queue for negative reviews to avoid tone-deaf automated responses."
    },
    {
      "type": "explainBack",
      "prompt": "Explain the AI tax and the four-step decision framework for evaluating whether AI is the right approach for a given feature."
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "Think of a feature in a system you work on that uses AI. Could it be replaced with a simpler approach?",
        "What organizational or social pressures push teams toward using AI when simpler tools would suffice?",
        "How would you push back on a stakeholder who insists on using AI for a problem where a rule engine would work better?"
      ]
    },
    {
      "type": "connectPrompt",
      "prompt": "How does the can-vs-should framework connect to the testing strategies from Module 4.5? Think about how the choice of technology affects your testing burden."
    },
    {
      "type": "keyTakeaway",
      "content": "The best AI engineers are not the ones who use AI for everything -- they are the ones who know when **not** to use it. Run every feature request through the decision framework: is the problem ambiguous, are simpler alternatives insufficient, is the failure cost acceptable, and does the total cost of ownership justify the AI tax? The right answer is often a regex, a SQL query, or a rule engine."
    }
  ]
}