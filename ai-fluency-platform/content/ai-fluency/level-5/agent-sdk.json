{
  "meta": {
    "title": "5.9 Building Custom Agents",
    "description": "Building agents programmatically with SDKs -- from tool definitions to deployment and testing strategies.",
    "level": "level-5",
    "slug": "agent-sdk",
    "order": 0,
    "isCheckpoint": false,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "markdown",
      "content": "# 5.9 Building Custom Agents"
    },
    {
      "type": "predictPrompt",
      "prompt": "You have been using pre-built AI agents (like Claude Code, Codex, Cline) throughout this course. These are powerful but general-purpose. What do you think changes when you build an agent from scratch using an SDK? What capabilities would you gain, and what would you lose compared to using a pre-built tool?"
    },
    {
      "type": "markdown",
      "content": "## SDK vs. Pre-Built Agents\n\nThe relationship between an agent SDK and a pre-built agent is like the relationship between a programming language and an application built with it:\n\n| Pre-Built Agent (e.g., Claude Code) | Agent SDK (e.g., Anthropic SDK) |\n|--------------------------------------|----------------------------------|\n| Ready to use immediately | Requires development effort |\n| General-purpose capabilities | Custom capabilities you define |\n| Configuration-driven customization | Code-level customization |\n| Fixed tool set (extensible via MCP) | Any tools you implement |\n| The vendor's UX decisions | Your UX decisions |\n| Limited deployment options | Deploy anywhere as code |\n\nUse a pre-built agent when it fits your workflow. Build a custom agent when you need:\n- **Domain-specific tools** that don't exist as MCP servers\n- **Custom conversation flows** (e.g., guided diagnostics, structured interviews)\n- **Embedded AI** in your own application (web app, CLI, Slack bot)\n- **Fine-grained control** over model selection, token budgets, and error handling\n- **Custom security boundaries** and permission models\n\n## The Anatomy of a Custom Agent\n\nEvery custom agent has four core components:\n\n```\n┌─────────────────────────────────────────┐\n│  1. System Prompt                       │\n│  (personality, constraints, behavior)   │\n├─────────────────────────────────────────┤\n│  2. Tool Definitions                    │\n│  (what the agent can do)                │\n├─────────────────────────────────────────┤\n│  3. Conversation Loop                   │\n│  (message handling, tool execution)     │\n├─────────────────────────────────────────┤\n│  4. Model Configuration                 │\n│  (which model, temperature, tokens)     │\n└─────────────────────────────────────────┘\n```"
    },
    {
      "type": "markdown",
      "content": "## Tool Definitions\n\nTools are the agent's interface to the outside world. Each tool definition needs:\n\n```typescript\nimport Anthropic from \"@anthropic-ai/sdk\";\n\n// Define tools with precise schemas\nconst tools: Anthropic.Tool[] = [\n  {\n    name: \"search_knowledge_base\",\n    description: \"Search the internal knowledge base for articles matching a query. Returns the top 5 results with titles, snippets, and relevance scores. Use this when the user asks a question that might be answered by existing documentation.\",\n    input_schema: {\n      type: \"object\" as const,\n      properties: {\n        query: {\n          type: \"string\",\n          description: \"Natural language search query\"\n        },\n        category: {\n          type: \"string\",\n          enum: [\"engineering\", \"product\", \"operations\", \"all\"],\n          description: \"Filter results to a specific category\"\n        },\n        max_results: {\n          type: \"number\",\n          description: \"Maximum number of results (1-20, default 5)\"\n        }\n      },\n      required: [\"query\"]\n    }\n  },\n  {\n    name: \"create_ticket\",\n    description: \"Create a support ticket in the ticketing system. Use this when the user's issue cannot be resolved from the knowledge base and needs human follow-up. Always confirm the ticket details with the user before creating.\",\n    input_schema: {\n      type: \"object\" as const,\n      properties: {\n        title: {\n          type: \"string\",\n          description: \"Brief title for the ticket\"\n        },\n        description: {\n          type: \"string\",\n          description: \"Detailed description of the issue\"\n        },\n        priority: {\n          type: \"string\",\n          enum: [\"low\", \"medium\", \"high\", \"urgent\"],\n          description: \"Ticket priority level\"\n        },\n        category: {\n          type: \"string\",\n          description: \"Issue category for routing\"\n        }\n      },\n      required: [\"title\", \"description\", \"priority\"]\n    }\n  },\n  {\n    name: \"get_user_context\",\n    description: \"Retrieve the current user's account information, recent tickets, and subscription status. Use this at the start of a conversation to personalize responses.\",\n    input_schema: {\n      type: \"object\" as const,\n      properties: {\n        user_id: {\n          type: \"string\",\n          description: \"The user's account ID\"\n        }\n      },\n      required: [\"user_id\"]\n    }\n  }\n];\n```\n\nNotice how each tool description explains not just *what* the tool does, but *when* to use it. This guides the model's decision-making."
    },
    {
      "type": "calibrationCheck",
      "question": "Why is the tool description 'Create a ticket' insufficient, while 'Create a support ticket in the ticketing system. Use this when the user's issue cannot be resolved from the knowledge base and needs human follow-up. Always confirm the ticket details with the user before creating.' is much better?",
      "answer": "The short description gives the model no guidance on **when** to use the tool or **how** to use it responsibly. The model might create tickets prematurely (before searching the knowledge base), create tickets without confirming details with the user, or misunderstand the tool's purpose entirely. The longer description provides three critical pieces of context: (1) what system it affects (the ticketing system), (2) when to use it (only after knowledge base search fails), and (3) a behavioral constraint (confirm with user first). Tool descriptions are the primary mechanism for controlling agent behavior -- they are effectively part of the system prompt that is scoped to a specific action."
    },
    {
      "type": "markdown",
      "content": "## The Conversation Loop\n\nThe heart of a custom agent is the conversation loop that handles user messages, processes tool calls, and manages state:\n\n```typescript\nimport Anthropic from \"@anthropic-ai/sdk\";\n\nconst client = new Anthropic();\n\ninterface AgentConfig {\n  model: string;\n  systemPrompt: string;\n  tools: Anthropic.Tool[];\n  maxTurns: number;\n  maxTokens: number;\n}\n\nasync function runAgent(\n  config: AgentConfig,\n  userMessage: string,\n  conversationHistory: Anthropic.MessageParam[] = []\n): Promise<{ response: string; history: Anthropic.MessageParam[] }> {\n  \n  const messages: Anthropic.MessageParam[] = [\n    ...conversationHistory,\n    { role: \"user\", content: userMessage }\n  ];\n\n  let turns = 0;\n\n  while (turns < config.maxTurns) {\n    turns++;\n\n    const response = await client.messages.create({\n      model: config.model,\n      max_tokens: config.maxTokens,\n      system: config.systemPrompt,\n      tools: config.tools,\n      messages\n    });\n\n    // If the model wants to use tools, execute them\n    if (response.stop_reason === \"tool_use\") {\n      // Add the assistant's response (with tool_use blocks)\n      messages.push({ role: \"assistant\", content: response.content });\n\n      // Execute each tool call and collect results\n      const toolResults: Anthropic.ToolResultBlockParam[] = [];\n      for (const block of response.content) {\n        if (block.type === \"tool_use\") {\n          const result = await executeTool(block.name, block.input);\n          toolResults.push({\n            type: \"tool_result\",\n            tool_use_id: block.id,\n            content: result\n          });\n        }\n      }\n\n      // Feed tool results back to the model\n      messages.push({ role: \"user\", content: toolResults });\n      continue;\n    }\n\n    // If the model produced a final text response, return it\n    if (response.stop_reason === \"end_turn\") {\n      messages.push({ role: \"assistant\", content: response.content });\n      const textContent = response.content\n        .filter((b): b is Anthropic.TextBlock => b.type === \"text\")\n        .map(b => b.text)\n        .join(\"\");\n      return { response: textContent, history: messages };\n    }\n  }\n\n  return {\n    response: \"I was not able to complete your request within the allowed number of steps.\",\n    history: messages\n  };\n}\n\n// Tool execution dispatcher\nasync function executeTool(\n  name: string,\n  input: Record<string, unknown>\n): Promise<string> {\n  switch (name) {\n    case \"search_knowledge_base\":\n      return await searchKnowledgeBase(input as any);\n    case \"create_ticket\":\n      return await createTicket(input as any);\n    case \"get_user_context\":\n      return await getUserContext(input as any);\n    default:\n      return JSON.stringify({ error: `Unknown tool: ${name}` });\n  }\n}\n```\n\nThis loop continues until either:\n1. The model produces a final text response (`end_turn`)\n2. The maximum number of turns is reached\n3. An unrecoverable error occurs"
    },
    {
      "type": "markdown",
      "content": "## Context Window Management\n\nAs conversations grow, you will hit context window limits. Strategies for managing this:\n\n### Sliding Window\nDrop the oldest messages when the context exceeds a threshold:\n\n```typescript\nfunction trimMessages(\n  messages: Anthropic.MessageParam[],\n  maxTokenEstimate: number\n): Anthropic.MessageParam[] {\n  let estimatedTokens = 0;\n  const result: Anthropic.MessageParam[] = [];\n  \n  // Always keep the first message (often contains key context)\n  // Then fill from the most recent messages backward\n  const first = messages[0];\n  const rest = messages.slice(1);\n  \n  for (let i = rest.length - 1; i >= 0; i--) {\n    const msgTokens = estimateTokens(rest[i]);\n    if (estimatedTokens + msgTokens > maxTokenEstimate) break;\n    estimatedTokens += msgTokens;\n    result.unshift(rest[i]);\n  }\n  \n  return [first, ...result];\n}\n```\n\n### Summarization\nPeriodically summarize the conversation history and replace old messages with the summary:\n\n```typescript\nasync function summarizeHistory(\n  messages: Anthropic.MessageParam[]\n): Promise<Anthropic.MessageParam> {\n  const summary = await client.messages.create({\n    model: \"claude-haiku-4-5-20251001\",  // use a fast model for summarization\n    max_tokens: 500,\n    messages: [\n      { role: \"user\", content: \n        `Summarize this conversation in 2-3 paragraphs, preserving key facts, ` +\n        `decisions, and any unresolved questions:\\n\\n` +\n        messages.map(m => `${m.role}: ${JSON.stringify(m.content)}`).join(\"\\n\")\n      }\n    ]\n  });\n  return {\n    role: \"user\",\n    content: `[Previous conversation summary]: ${summary.content[0].type === \"text\" ? summary.content[0].text : \"\"}`\n  };\n}\n```"
    },
    {
      "type": "calibrationCheck",
      "question": "What is the tradeoff between the sliding window and summarization approaches to context management? When would each fail?",
      "answer": "**Sliding window** is simple and cheap but lossy -- it drops old messages entirely, which means the agent forgets early context. It fails when early messages contain critical information (e.g., the user stated a constraint in message 2 that affects message 50). **Summarization** preserves key information but is more expensive (requires an extra API call), slower, and potentially inaccurate (the summarizer might miss or distort important details). It fails when the conversation contains precise technical details that resist summarization (e.g., specific code snippets, exact parameter values, or nuanced constraints). The best approach often combines both: summarize periodically, then apply a sliding window within each summary epoch. Critical information (like the user's original request and any stated constraints) should be pinned and never dropped."
    },
    {
      "type": "markdown",
      "content": "## End-to-End Example: Knowledge Base Q&A Agent\n\nPutting it all together -- a complete agent that answers questions using an internal knowledge base:\n\n```typescript\nimport Anthropic from \"@anthropic-ai/sdk\";\n\nconst client = new Anthropic();\n\nconst SYSTEM_PROMPT = `You are a helpful support agent for Acme Corp.\nYou answer questions using the internal knowledge base.\n\nBehavior rules:\n1. Always search the knowledge base before answering from general knowledge.\n2. If the knowledge base has a relevant article, cite it by title.\n3. If no relevant article exists, say so honestly and offer to create a ticket.\n4. Before creating a ticket, confirm the details with the user.\n5. Be concise and professional. Avoid jargon the user has not used.\n6. Never make up information. If unsure, say so.`;\n\nconst tools: Anthropic.Tool[] = [\n  {\n    name: \"search_knowledge_base\",\n    description: \"Search internal docs. Returns titles, snippets, and relevance scores.\",\n    input_schema: {\n      type: \"object\" as const,\n      properties: {\n        query: { type: \"string\", description: \"Search query\" },\n        max_results: { type: \"number\", description: \"Max results (default 5)\" }\n      },\n      required: [\"query\"]\n    }\n  },\n  {\n    name: \"create_ticket\",\n    description: \"Create a support ticket. Confirm details with user first.\",\n    input_schema: {\n      type: \"object\" as const,\n      properties: {\n        title: { type: \"string\" },\n        description: { type: \"string\" },\n        priority: { type: \"string\", enum: [\"low\", \"medium\", \"high\"] }\n      },\n      required: [\"title\", \"description\", \"priority\"]\n    }\n  }\n];\n\n// Main entry point\nasync function handleUserQuery(query: string) {\n  const result = await runAgent(\n    {\n      model: \"claude-sonnet-4-5-20250929\",\n      systemPrompt: SYSTEM_PROMPT,\n      tools,\n      maxTurns: 10,\n      maxTokens: 1024\n    },\n    query\n  );\n  return result.response;\n}\n```\n\nThis is a production-ready skeleton. In a real deployment, you would add authentication, rate limiting, error handling, logging, and metrics collection around this core."
    },
    {
      "type": "markdown",
      "content": "## Deployment Patterns\n\nCustom agents can be deployed in several forms:\n\n### 1. Agent as a Service (API)\nDeploy the agent behind an HTTP API. Clients send messages and receive responses.\n\n```typescript\n// Express.js example\napp.post(\"/api/chat\", async (req, res) => {\n  const { message, sessionId } = req.body;\n  const history = await loadHistory(sessionId);\n  const result = await runAgent(config, message, history);\n  await saveHistory(sessionId, result.history);\n  res.json({ response: result.response });\n});\n```\n\n**Considerations**: Session management (where to store conversation history), scaling (one API call may trigger multiple model calls), timeout handling (agent loops can take time).\n\n### 2. Agent as a CLI Tool\nBuild a command-line interface for developer-facing agents.\n\n```typescript\nimport * as readline from \"readline\";\n\nconst rl = readline.createInterface({ input: process.stdin, output: process.stdout });\nlet history: Anthropic.MessageParam[] = [];\n\nfunction prompt() {\n  rl.question(\"You: \", async (input) => {\n    if (input === \"exit\") { rl.close(); return; }\n    const result = await runAgent(config, input, history);\n    history = result.history;\n    console.log(`Agent: ${result.response}`);\n    prompt();\n  });\n}\nprompt();\n```\n\n### 3. Agent Embedded in a Web App\nEmbed the agent in a React/Next.js application with streaming responses.\n\nThe deployment choice depends on who uses the agent and how. Internal developer tools favor CLIs. Customer-facing products favor web apps. Integration-heavy systems favor APIs.\n\n## Testing Custom Agents\n\nTesting agents is challenging because they are non-deterministic. Strategies:\n\n### Tool Call Assertions\nVerify that the agent calls the right tools with the right arguments:\n\n```typescript\ntest(\"agent searches knowledge base before answering\", async () => {\n  const toolCalls: { name: string; input: any }[] = [];\n  \n  // Mock executeTool to record calls\n  const originalExecute = executeTool;\n  executeTool = async (name, input) => {\n    toolCalls.push({ name, input });\n    return JSON.stringify({ results: [{ title: \"Test Article\", snippet: \"...\" }] });\n  };\n\n  await runAgent(config, \"How do I reset my password?\");\n  \n  // Assert the agent searched before responding\n  expect(toolCalls.length).toBeGreaterThan(0);\n  expect(toolCalls[0].name).toBe(\"search_knowledge_base\");\n  expect(toolCalls[0].input.query).toContain(\"password\");\n  \n  executeTool = originalExecute;\n});\n```\n\n### Behavioral Assertions\nCheck that the agent's final response meets quality criteria:\n\n```typescript\ntest(\"agent does not hallucinate when KB has no results\", async () => {\n  // Mock KB to return empty results\n  mockKnowledgeBase([]);\n  \n  const result = await runAgent(config, \"How do I fly to the moon?\");\n  \n  // Agent should acknowledge it cannot help, not make up an answer\n  expect(result.response).toMatch(/don't have|no.*article|couldn't find|not able/i);\n  expect(result.response).toMatch(/ticket|support|help/i); // should offer escalation\n});\n```\n\n### Snapshot Tests\nCapture the full sequence of tool calls and responses for known inputs, then alert on changes:\n\n```typescript\ntest(\"password reset flow snapshot\", async () => {\n  const trace = await runAgentWithTrace(config, \"How do I reset my password?\");\n  expect(trace.toolCalls).toMatchSnapshot();\n  // Snapshot includes: which tools were called, in what order, with what args\n  // Update snapshots deliberately when agent behavior intentionally changes\n});\n```\n\nThe key insight: you cannot test the exact text output (it is non-deterministic), but you *can* test the agent's behavior -- what tools it calls, when it escalates, and whether it follows its stated rules."
    },
    {
      "type": "tryItYourself",
      "title": "Design a custom agent for your domain. Define: (1) The system prompt with behavioral rules, (2) At least 3 typed tools with full schemas, (3) The deployment pattern (API, CLI, or web app), and (4) Three test cases that verify behavior, not exact text output.",
      "solution": "**Example: DevOps Incident Response Agent**\n\n**System Prompt:**\n\"You are an incident response agent for a cloud infrastructure team. When alerted about an issue, you diagnose the problem using monitoring tools, suggest remediation steps, and create incident tickets. Rules: (1) Always check service health before suggesting fixes. (2) Never execute destructive commands without explicit user approval. (3) Escalate to on-call if the issue affects more than 3 services. (4) Log all actions in the incident timeline.\"\n\n**Tools:**\n1. `check_service_health` -- Input: { service_name: string }. Returns: status, latency_p99, error_rate, last_deploy_time.\n2. `query_logs` -- Input: { service: string, time_range: string, filter: string }. Returns: matching log entries with timestamps.\n3. `create_incident` -- Input: { title: string, severity: 'sev1'|'sev2'|'sev3', affected_services: string[], description: string }. Returns: incident ID and URL.\n4. `notify_oncall` -- Input: { incident_id: string, message: string }. Returns: confirmation of notification sent.\n\n**Deployment:** API service running in Kubernetes, triggered by PagerDuty webhooks. Responses are posted to the incident's Slack channel.\n\n**Test Cases:**\n1. **Diagnosis before action:** Given an alert about high latency in the payments service, assert the agent calls `check_service_health` for payments (and likely its dependencies) before suggesting fixes.\n2. **Escalation threshold:** Given an issue affecting 4 services, assert the agent calls `create_incident` with sev1 or sev2 AND calls `notify_oncall`.\n3. **No destructive actions:** Given a suggestion to restart a service, assert the agent's response includes a confirmation prompt (\"Should I proceed?\") rather than executing immediately."
    },
    {
      "type": "explainBack",
      "prompt": "Explain to a developer who has used ChatGPT but never built a custom agent: what an agent SDK gives you, how the conversation loop works (including tool execution), and why testing agents is different from testing regular functions."
    },
    {
      "type": "keyTakeaway",
      "content": "Building custom agents with SDKs gives you full control over tools, conversation flow, model configuration, and deployment. Every agent has four core components: a system prompt, tool definitions, a conversation loop, and model configuration. The conversation loop handles the tool-calling cycle (model requests tool, your code executes it, result feeds back). Context window management through sliding windows or summarization prevents conversation overflow. Deploy agents as APIs, CLIs, or embedded in web apps. Test agents by asserting on behavior (tool calls, escalation decisions, rule compliance) rather than exact text output."
    },
    {
      "type": "connectPrompt",
      "prompt": "How do the deterministic wrapper patterns from Level 4 apply to custom agent development? How would you wrap a non-deterministic agent in a deterministic interface for consumers of your API?"
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "What domain-specific agent would be most valuable in your work? What tools would it need, and what behavioral rules would you encode in the system prompt?",
        "How would you handle the versioning problem -- when you update an agent's system prompt or tools, how do you ensure existing conversations are not disrupted?",
        "What is the minimum level of testing you would require before deploying a custom agent that interacts with customers or modifies production data?"
      ]
    },
    {
      "type": "providerContent",
      "context": "Each AI provider offers different SDKs and approaches for building custom agents programmatically.",
      "providers": {
        "claude-code": "## Anthropic: Agent SDK and Claude API\n\nAnthropic provides two complementary paths for building custom agents.\n\n### Claude API with Tool Use\n\nThe Anthropic SDK (`@anthropic-ai/sdk`) provides direct access to Claude models with native tool use support. This is the foundation shown throughout this module.\n\n```typescript\nimport Anthropic from \"@anthropic-ai/sdk\";\n\nconst client = new Anthropic();\n\n// Create a message with tools\nconst response = await client.messages.create({\n  model: \"claude-sonnet-4-5-20250929\",\n  max_tokens: 1024,\n  system: \"You are a helpful assistant.\",\n  tools: [/* tool definitions */],\n  messages: [{ role: \"user\", content: \"Hello\" }]\n});\n```\n\n### Anthropic Agent SDK\n\nThe Agent SDK builds on top of the base API to provide higher-level abstractions for agent development:\n- **Agent class** with built-in conversation management\n- **Tool decorators** for simpler tool definitions\n- **Conversation hooks** for middleware (logging, validation, cost tracking)\n- **Streaming support** for real-time response delivery\n\n### MCP Integration\n\nCustom agents built with the Anthropic SDK can act as MCP clients, connecting to any MCP server. This means your custom agent can instantly gain access to the entire MCP tool ecosystem without implementing each tool from scratch.\n\n```typescript\n// Connect your custom agent to MCP servers\nimport { McpClient } from \"@modelcontextprotocol/sdk/client/mcp.js\";\n\nconst mcpTools = await mcpClient.listTools();\nconst allTools = [...customTools, ...convertMcpTools(mcpTools)];\n```\n\nThis is a powerful pattern: define your domain-specific tools directly, and pull in general-purpose tools from MCP servers.",
        "codex": "## OpenAI: Agents SDK and Function Calling\n\nOpenAI provides multiple layers for building custom agents.\n\n### Function Calling (Base API)\n\nThe foundational approach uses the Chat Completions or Responses API with function definitions:\n\n```python\nfrom openai import OpenAI\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": \"What is the weather?\"}],\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get the current weather\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\"type\": \"string\"}\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    }]\n)\n```\n\n### OpenAI Agents SDK\n\nThe Agents SDK (`openai-agents`) provides a higher-level framework:\n\n```python\nfrom openai import agents\n\nagent = agents.Agent(\n    name=\"support-agent\",\n    model=\"gpt-4o\",\n    instructions=\"You are a helpful support agent.\",\n    tools=[search_tool, ticket_tool]\n)\n\nresult = agents.Runner.run_sync(agent, \"Help me reset my password\")\n```\n\nKey features include built-in handoffs (delegating between agents), guardrails (input/output validation), and tracing for debugging agent behavior.\n\n### Assistants API\n\nThe Assistants API provides a managed, stateful agent experience with built-in conversation threading, file handling, and code interpretation. It abstracts away the conversation loop entirely -- you create an assistant, add messages to threads, and run the assistant on the thread.",
        "cline": "## Cline: Building Extensions and Custom Tool Providers\n\nCline's extensibility model focuses on VS Code extensions and custom tool providers.\n\n### Custom Tool Providers\n\nYou can extend Cline's capabilities by building MCP servers that Cline connects to. This is the primary path for adding custom tools:\n\n1. Build an MCP server that exposes your domain-specific tools\n2. Configure Cline to connect to the server\n3. Cline's AI can now discover and use your tools\n\n### VS Code Extension Integration\n\nFor deeper integration, you can build VS Code extensions that interact with Cline's API:\n- Provide custom context to Cline based on workspace state\n- Add custom commands that trigger Cline with pre-configured prompts\n- Intercept and modify Cline's tool calls for domain-specific validation\n\n### Building a Cline-Like Agent\n\nIf you want to build a completely custom agent (not extending Cline), the patterns from this module apply directly. Use the Anthropic or OpenAI SDK, define your tools, implement the conversation loop, and deploy. Cline itself is built on these same principles -- it is a custom agent implemented as a VS Code extension with a specific set of tools (file read/write, terminal, browser) and a conversation loop that handles user interaction.",
        "gemini": "## Gemini: ADK and Vertex AI Agents\n\nGoogle provides the Agent Development Kit (ADK) and Vertex AI for building custom agents.\n\n### Agent Development Kit (ADK)\n\nADK is Google's open-source framework for building agents with Gemini models:\n\n```python\nfrom google.adk import Agent, Tool\nfrom google.genai import types\n\n# Define a tool\ndef search_documents(query: str) -> str:\n    \"\"\"Search internal documents for relevant information.\"\"\"\n    results = document_store.search(query)\n    return json.dumps(results)\n\n# Create an agent\nagent = Agent(\n    name=\"support-agent\",\n    model=\"gemini-2.5-pro\",\n    instruction=\"You help users find information in our documentation.\",\n    tools=[search_documents]\n)\n\n# Run the agent\nresponse = agent.run(\"How do I configure SSO?\")\n```\n\nADK provides built-in support for:\n- **Tool definitions** using Python function signatures (auto-generates schemas)\n- **Multi-agent coordination** with sub-agents and handoffs\n- **Session management** with built-in conversation state\n- **Evaluation** tools for testing agent behavior\n\n### Vertex AI Agent Builder\n\nFor production deployments, Vertex AI Agent Builder provides a managed platform:\n- Deploy agents as scalable services on Google Cloud\n- Built-in monitoring, logging, and A/B testing\n- Integration with Google Cloud services (BigQuery, Cloud Storage, Pub/Sub)\n- Enterprise security with IAM and VPC controls\n\n### Key Differentiator\n\nADK's use of Python function signatures for tool definitions is notably ergonomic -- you write a normal Python function with type hints and a docstring, and ADK generates the tool schema automatically. This reduces the boilerplate compared to manual JSON schema definitions."
      }
    }
  ]
}