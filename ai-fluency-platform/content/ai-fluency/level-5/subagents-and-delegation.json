{
  "meta": {
    "title": "5.7 Subagents and Delegation",
    "description": "Spawning specialized agents for parallel work with isolated context, typed capabilities, and structured delegation.",
    "level": "level-5",
    "slug": "subagents-and-delegation",
    "order": 0,
    "isCheckpoint": false,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "markdown",
      "content": "# 5.7 Subagents and Delegation"
    },
    {
      "type": "predictPrompt",
      "prompt": "When a single AI agent is working on a large task -- say, auditing a 500-file codebase -- it will eventually hit context window limits and lose track of earlier findings. How might you solve this? What if the agent could spawn separate 'helper' agents, each working on a smaller piece with their own context?"
    },
    {
      "type": "markdown",
      "content": "## What Is a Subagent?\n\nA subagent is a separate AI instance spawned by a parent agent to handle a specific subtask. The key properties that distinguish a subagent from just \"another prompt\" are:\n\n1. **Separate context**: The subagent has its own conversation history and context window, isolated from the parent\n2. **Scoped tools**: The subagent can be given a different set of tools than the parent\n3. **Defined lifecycle**: The subagent starts, does its work, returns a result, and terminates\n4. **Parent control**: The parent decides when to spawn, what to delegate, and how to use the result\n\nThe mental model is a manager delegating to a specialist. The manager does not dump their entire notebook on the specialist's desk -- they provide a focused brief, the specialist works independently, and they return a summary.\n\n```\n┌──────────────────────────────────────┐\n│  Parent Agent                        │\n│  Context: full project understanding │\n│  Tools: all tools                    │\n│                                      │\n│  \"I need to analyze auth, db, and    │\n│   API security separately\"           │\n│         │          │          │      │\n│    ┌────┴───┐ ┌────┴───┐ ┌───┴────┐ │\n│    │ Sub A  │ │ Sub B  │ │ Sub C  │ │\n│    │ Auth   │ │ DB     │ │ API    │ │\n│    │ audit  │ │ audit  │ │ audit  │ │\n│    └────┬───┘ └────┬───┘ └───┬────┘ │\n│         │          │         │      │\n│    Results flow back to parent       │\n└──────────────────────────────────────┘\n```"
    },
    {
      "type": "calibrationCheck",
      "question": "Why would you use a subagent instead of just putting everything into one long conversation with a single agent? What specific problems does context isolation solve?",
      "answer": "A single agent conversation has several failure modes that subagents address: (1) **Context window saturation** -- as the conversation grows, the model loses track of earlier details and performance degrades. Subagents start fresh with only the relevant context. (2) **Cross-contamination** -- findings from one area (e.g., auth code) might bias the model's analysis of another area (e.g., database code). Isolation prevents this. (3) **Parallelism** -- a single agent works sequentially, but multiple subagents can work in parallel on independent tasks. (4) **Focused tool access** -- a read-only subagent cannot accidentally modify files, reducing the blast radius of errors. (5) **Cost efficiency** -- each subagent's context window is smaller, meaning fewer tokens per request and lower cost per step."
    },
    {
      "type": "markdown",
      "content": "## Agent Types and Capabilities\n\nNot every subagent needs full power. Restricting capabilities follows the principle of least privilege:\n\n### Read-Only Agents\n- **Tools**: File reading, search, grep -- no write or execute\n- **Use case**: Research, analysis, code review, finding patterns\n- **Risk profile**: Cannot cause damage; can only observe\n\n### Terminal Agents\n- **Tools**: Read + command execution (build, test, lint)\n- **Use case**: Running test suites, checking build status, validating configurations\n- **Risk profile**: Can execute commands but not modify source code directly\n\n### Full-Capability Agents\n- **Tools**: Read + write + execute + network\n- **Use case**: Implementing features, fixing bugs, refactoring code\n- **Risk profile**: Highest -- can make permanent changes\n\n```typescript\n// Conceptual capability definition\ninterface SubagentConfig {\n  name: string;\n  description: string;\n  capabilities: (\"read\" | \"write\" | \"execute\" | \"network\")[];\n  tools: string[];  // specific tools to provide\n  maxTurns: number; // limit how long the subagent can run\n  context: string;  // the brief to pass to the subagent\n}\n\n// Read-only research subagent\nconst researcher: SubagentConfig = {\n  name: \"security-researcher\",\n  description: \"Analyze source code for security vulnerabilities\",\n  capabilities: [\"read\"],\n  tools: [\"read_file\", \"search_files\", \"grep\"],\n  maxTurns: 30,\n  context: \"Examine the auth module in src/auth/ for common vulnerabilities: SQL injection, XSS, CSRF, insecure session handling. Report findings with file paths and line numbers.\"\n};\n```"
    },
    {
      "type": "markdown",
      "content": "## Delegation Strategy: When to Spawn vs. Handle Directly\n\nDelegation has overhead -- spawning a subagent costs time and tokens for the handoff. Not every subtask benefits. Use this decision framework:\n\n**Delegate when:**\n- The subtask is **independent** and does not need the parent's full context\n- The subtask would consume significant context window if done inline\n- Multiple subtasks can run **in parallel**\n- The subtask needs **different tool permissions** than the parent\n- The subtask is **well-defined** with clear inputs and expected outputs\n\n**Handle directly when:**\n- The subtask is **small** (a few tool calls)\n- The subtask **depends heavily** on the parent's accumulated context\n- The subtask requires **back-and-forth** with the parent (frequent check-ins)\n- The overhead of delegation exceeds the benefit\n\n### The Delegation Brief\n\nThe quality of a delegation depends on the brief. A good brief includes:\n1. **Objective**: What the subagent should accomplish\n2. **Scope**: What files, directories, or systems to focus on\n3. **Constraints**: What the subagent should NOT do\n4. **Output format**: How results should be structured\n5. **Stop conditions**: When the subagent should consider itself done\n\n```\nBad brief:  \"Look at the code and find problems.\"\n\nGood brief: \"Analyze all files in src/api/routes/ for input validation\n             issues. For each route handler, check whether user input\n             is validated before being used in database queries or\n             passed to external services. Report each finding as:\n             {file, line, issue, severity, recommendation}.\n             Do not modify any files. Stop after reviewing all route\n             files or after 20 minutes of work.\"\n```"
    },
    {
      "type": "calibrationCheck",
      "question": "A parent agent delegates a task to a subagent with the brief: 'Fix all the bugs in the authentication module.' What is wrong with this delegation, and how should it be restructured?",
      "answer": "This delegation fails on multiple levels: (1) **Scope is unbounded** -- 'all the bugs' has no clear stopping condition and the subagent might chase false positives indefinitely. (2) **No context** -- the subagent does not know which bugs are known, which are priorities, or what 'fixed' looks like. (3) **Output is ambiguous** -- should it make the fixes itself, or report them? (4) **No permission scoping** -- fixing bugs requires write access, but should a delegated subagent make unsupervised changes to auth code? A better approach: first delegate a read-only audit ('Identify the top 5 authentication vulnerabilities in src/auth/, ranked by severity, with specific file/line references'), then review the findings, then delegate individual fixes with precise instructions ('In src/auth/session.ts line 42, add input validation for the session token using the pattern...') or fix them yourself."
    },
    {
      "type": "markdown",
      "content": "## Context Isolation: What to Pass vs. What to Omit\n\nContext isolation is both the main advantage and the main challenge of subagents. Pass too little context and the subagent flounders. Pass too much and you negate the benefits of isolation.\n\n### What to Pass\n- The specific task description (the brief)\n- File paths or code snippets directly relevant to the task\n- Relevant conventions, patterns, or constraints (e.g., \"this project uses ESM, not CommonJS\")\n- Expected output format\n\n### What to Omit\n- The parent's full conversation history\n- Unrelated project context (e.g., don't tell the DB auditor about the frontend architecture)\n- Previous subagent results (unless there's a direct dependency)\n- Meta-information about the parent's planning process\n\nThe goal is to give the subagent everything it needs to do its job *and nothing more*. This keeps the subagent's context clean and focused.\n\n## Error Handling When Subagents Fail\n\nSubagents can fail in several ways:\n\n1. **Timeout**: The subagent exceeds its step or time limit without completing\n2. **Scope drift**: The subagent wanders off-task and returns irrelevant results\n3. **Tool failure**: A tool the subagent depends on is unavailable or errors\n4. **Contradictory results**: Multiple subagents return conflicting findings\n5. **Incomplete results**: The subagent returns partial results without acknowledging gaps\n\n### Handling Strategies\n\n```typescript\nasync function delegateWithRetry(\n  task: SubagentConfig,\n  maxRetries: number = 2\n): Promise<SubagentResult> {\n  for (let attempt = 0; attempt <= maxRetries; attempt++) {\n    const result = await spawnSubagent(task);\n    \n    if (result.status === \"complete\" && isResultValid(result)) {\n      return result;\n    }\n    \n    if (result.status === \"timeout\") {\n      // Narrow the scope and retry\n      task.context += \"\\nIMPORTANT: Focus on the most critical items only. \" +\n        \"You previously timed out. Limit your analysis to the top 3 findings.\";\n      continue;\n    }\n    \n    if (result.status === \"error\") {\n      // Adjust tools or context and retry\n      task.tools = task.tools.filter(t => t !== result.failedTool);\n      continue;\n    }\n  }\n  \n  // Fall back to handling it in the parent\n  return { status: \"escalated\", reason: \"Subagent failed after retries\" };\n}\n```\n\nThe parent should always validate subagent results before acting on them. Trust but verify -- especially for subagents that had write permissions."
    },
    {
      "type": "tryItYourself",
      "title": "Design a delegation plan for a codebase security audit. You have a 200-file TypeScript project with auth, database, API, and frontend modules. Define at least 3 subagents with their types, capabilities, briefs, and expected outputs. Explain how the parent coordinates and synthesizes results.",
      "solution": "**Subagent 1: Auth Module Auditor (Read-Only)**\n- Capabilities: read, search\n- Brief: \"Examine all files in src/auth/ and src/middleware/. Check for: hardcoded secrets, insecure session management, missing CSRF protection, weak password hashing, improper token validation. Report each finding as {file, line, category, severity, description, recommendation}.\"\n- Expected output: JSON array of findings, sorted by severity\n- Max turns: 25\n\n**Subagent 2: Database Layer Auditor (Read-Only)**\n- Capabilities: read, search\n- Brief: \"Examine all files in src/db/ and src/models/. Check for: SQL injection via string concatenation, missing parameterized queries, overly permissive queries (SELECT *), missing transaction boundaries for multi-step operations, sensitive data stored in plaintext. Report each finding as {file, line, category, severity, description, recommendation}.\"\n- Expected output: JSON array of findings, sorted by severity\n- Max turns: 25\n\n**Subagent 3: API Surface Auditor (Read-Only)**\n- Capabilities: read, search\n- Brief: \"Examine all files in src/api/ and src/routes/. Check for: missing input validation, missing rate limiting, verbose error messages that leak internals, missing authentication on protected routes, CORS misconfiguration. Report each finding as {file, line, category, severity, description, recommendation}.\"\n- Expected output: JSON array of findings, sorted by severity\n- Max turns: 25\n\n**Parent Coordination:**\n1. Spawn all 3 subagents in parallel\n2. Collect results, validate each finding (reject duplicates, check file paths exist)\n3. Cross-reference: if the auth auditor found weak token validation AND the API auditor found unprotected routes, elevate the combined risk\n4. Produce a unified report: critical findings first, grouped by category, with a summary of systemic patterns\n5. If any subagent timed out or returned incomplete results, re-delegate with a narrower scope or handle the remaining files directly"
    },
    {
      "type": "explainBack",
      "prompt": "Explain to a technical manager why you would use subagents instead of one powerful agent for a large task. Cover context isolation, parallel execution, and the principle of least privilege. Use an analogy from traditional software engineering or team management."
    },
    {
      "type": "keyTakeaway",
      "content": "Subagents are separate AI instances spawned for specific subtasks with isolated context, scoped tools, and defined lifecycles. They solve context window saturation, enable parallel work, and enforce least privilege through typed capabilities (read-only, terminal, full). Effective delegation requires well-structured briefs with clear objectives, scope, constraints, and output formats. The parent must validate subagent results and handle failures through retries, scope narrowing, or escalation."
    },
    {
      "type": "connectPrompt",
      "prompt": "How does the concept of subagent delegation relate to the microservices pattern in software architecture? What parallels do you see between context isolation in subagents and bounded contexts in domain-driven design?"
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "Think about a recent large task you did with an AI assistant. Would it have benefited from being split across multiple subagents? Where would you draw the boundaries?",
        "What organizational or cultural parallels do you see between AI subagent delegation and how human teams divide work? What lessons transfer?",
        "How would you build trust in a subagent's output? What verification steps would you require before acting on its findings?"
      ]
    },
    {
      "type": "providerContent",
      "context": "Subagent capabilities vary significantly across AI coding tools. Here is how each provider implements delegation and parallel work.",
      "providers": {
        "claude-code": "## Claude Code: Task Tool and Agent Types\n\nClaude Code implements subagents through the **Task tool**, which spawns a new Claude instance with its own context window and tool set.\n\n### Agent Types\n\nWhen using the Task tool, you can specify a `subagent_type` to control capabilities:\n\n- **`Explore`**: Read-only agent optimized for codebase exploration. Has access to Glob, Grep, Read, and Bash (read-only commands). Best for research, finding patterns, and understanding code without risk of modification.\n- **General-purpose**: Full-capability agent with access to all tools. Use for tasks that require reading, writing, and executing.\n\n### Spawning a Subagent\n\n```\nTask tool call:\n  description: \"Find all API endpoints that lack input validation\"\n  subagent_type: Explore\n  prompt: \"Search src/api/ for route handlers. For each handler,\n           check if req.body or req.params are validated before use.\n           Return a list of {file, line, handler, issue}.\"\n```\n\nThe subagent runs independently, uses its own context window, and returns its findings to the parent.\n\n### Background Agents\n\nClaude Code also supports background agents that can work on tasks while you continue interacting with the main agent. Background agents are useful for long-running tasks like test suites or comprehensive code reviews.\n\n### Practical Patterns\n\n- Use `Explore` subagents for any research or analysis task to protect the main context from large file reads\n- Set `max_turns` to prevent subagents from running indefinitely\n- The parent agent's context window is protected from the subagent's tool outputs -- only the final result comes back\n- Multiple Task tool calls in the same response run in parallel, enabling concurrent work",
        "codex": "## Codex: Sandboxed Execution Model\n\nOpenAI's Codex CLI takes a different approach to delegation. Rather than explicit subagent spawning, Codex uses a **sandboxed execution model** where each task runs in an isolated Docker container.\n\n### Isolation by Default\n\nEvery Codex task runs in a sandboxed environment with:\n- A copy of your repository\n- Network disabled by default (can be enabled with `--full-auto`)\n- File system changes tracked and presented as a diff\n\nThis means each \"subagent\" is inherently isolated -- it cannot affect the host system or other tasks.\n\n### Multi-Step Tasks\n\nCodex handles multi-step tasks within a single agent loop rather than spawning subagents. The agent can:\n- Read files and search the codebase\n- Write and modify files\n- Run tests and build commands\n- Apply patches to multiple files\n\n### Practical Delegation\n\nWhile Codex does not have an explicit subagent API, you can achieve parallel work by running multiple Codex instances on different branches or directories, then merging results. The sandboxed model ensures each instance cannot interfere with the others.",
        "cline": "## Cline: Multi-Step Task Delegation in VS Code\n\nCline handles complex tasks through iterative execution within VS Code, with each step building on the previous.\n\n### Task Execution Model\n\nCline processes tasks as a sequence of steps, where each step can involve:\n- Reading files for context\n- Searching the codebase\n- Making edits to files\n- Running terminal commands\n- Asking the user for clarification\n\n### Delegating Complex Work\n\nWhile Cline does not have a built-in subagent system, you can structure complex work by:\n- Breaking tasks into focused, sequential requests\n- Using Cline's ability to read and modify multiple files in a single session\n- Leveraging VS Code's multi-root workspace support to scope work to specific directories\n\n### Community Extensions\n\nThe Cline ecosystem includes community extensions that add multi-agent capabilities, allowing users to configure specialized agent profiles with different system prompts and tool access for different types of tasks (e.g., a \"reviewer\" profile vs. a \"coder\" profile).",
        "gemini": "## Gemini and Jules: Subtask Handling\n\nGoogle's AI coding tools approach delegation through the Agent Development Kit (ADK) and Jules.\n\n### Jules' Task Model\n\nJules, Google's asynchronous coding agent, handles complex tasks by breaking them into subtasks internally. When given a large task, Jules:\n- Creates a plan with discrete steps\n- Executes each step with access to the full repository\n- Produces a changeset (similar to a pull request) as output\n\n### ADK Subagents\n\nThe Agent Development Kit (ADK) provides explicit subagent support:\n\n```python\nfrom google.adk import Agent, SubAgent\n\n# Define a specialized subagent\nsecurity_auditor = SubAgent(\n    name=\"security-auditor\",\n    model=\"gemini-2.5-pro\",\n    tools=[read_file, search_code],\n    instruction=\"You are a security auditor. Analyze code for vulnerabilities.\"\n)\n\n# Parent agent can delegate to subagents\nparent = Agent(\n    name=\"project-manager\",\n    model=\"gemini-2.5-pro\",\n    sub_agents=[security_auditor],\n    instruction=\"Coordinate security audits by delegating to specialists.\"\n)\n```\n\nADK subagents have their own context, tools, and instructions, closely matching the subagent pattern described in this module. They communicate through structured message passing and can run in parallel."
      }
    }
  ]
}