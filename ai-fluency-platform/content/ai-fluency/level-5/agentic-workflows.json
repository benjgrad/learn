{
  "meta": {
    "title": "5.5 Agentic Workflows",
    "description": "ReAct prompting, tool use, multi-agent systems, and orchestration patterns for autonomous AI.",
    "level": "level-5",
    "slug": "agentic-workflows",
    "order": 0,
    "isCheckpoint": false,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "markdown",
      "content": "# 5.5 Agentic Workflows"
    },
    {
      "type": "predictPrompt",
      "prompt": "Standard AI interactions are one-shot: user asks, model responds. What would change if the model could use tools, take actions, and run multi-step plans autonomously? What new risks and opportunities emerge?"
    },
    {
      "type": "markdown",
      "content": "## From Chat to Agency\n\nThe three modes of AI engagement define a progression:\n\n1. **Automation**: AI performs a single defined task (summarize this, classify that)\n2. **Augmentation**: Human and AI think together (co-writing, code review)\n3. **Agency**: AI works independently, making decisions and taking actions on behalf of the human\n\nAgentic workflows live in the third mode. An AI agent is a system where the model:\n- **Observes** the current state\n- **Reasons** about what to do next\n- **Acts** by calling tools or producing outputs\n- **Reflects** on the results to decide the next step\n\nThis loop continues until the task is complete or the agent decides it needs human input.\n\n## ReAct: Reasoning + Acting\n\nThe ReAct framework (Reasoning and Acting) interleaves thinking with tool use. Instead of generating a complete answer from memory, the model reasons about what it needs, uses a tool to get real information, then continues reasoning.\n\n```\nUser: What was Apple's stock price change on its last earnings day?\n\nThought: I need to find Apple's most recent earnings date, then look up\n         the stock price change on that day.\nAction: search(\"Apple AAPL most recent earnings date 2026\")\nObservation: Apple reported Q1 2026 earnings on January 30, 2026.\n\nThought: Now I need the stock price change on January 30, 2026.\nAction: lookup_stock_price(\"AAPL\", \"2026-01-30\")\nObservation: Open: $242.50, Close: $251.80, Change: +3.83%\n\nThought: I have both pieces of information. I can now answer.\nAnswer: Apple's stock rose 3.83% on its most recent earnings day\n        (January 30, 2026), closing at $251.80.\n```\n\nThe key advantage of ReAct over pure generation is **grounding** -- the model's claims are based on real tool outputs, not memory that might be stale or incorrect.\n\n### Implementing a ReAct Loop\n\n```typescript\ninterface Tool {\n  name: string;\n  description: string;\n  parameters: Record<string, unknown>;\n  execute: (params: Record<string, unknown>) => Promise<string>;\n}\n\nasync function reactLoop(\n  query: string,\n  tools: Tool[],\n  maxSteps: number = 10\n): Promise<string> {\n  const messages = [\n    { role: \"system\", content: buildSystemPrompt(tools) },\n    { role: \"user\", content: query },\n  ];\n\n  for (let step = 0; step < maxSteps; step++) {\n    const response = await callModel(messages, { tools });\n\n    if (response.type === \"text\") {\n      return response.content; // Agent decided to answer\n    }\n\n    if (response.type === \"tool_call\") {\n      const tool = tools.find(t => t.name === response.toolName);\n      const result = await tool.execute(response.parameters);\n\n      messages.push(\n        { role: \"assistant\", content: response.raw },\n        { role: \"tool\", content: result },\n      );\n    }\n  }\n\n  return \"Agent reached maximum steps without a final answer.\";\n}\n```"
    },
    {
      "type": "calibrationCheck",
      "question": "What is the main risk of a ReAct agent compared to a simple prompt-and-respond system? Why does adding tool use increase the potential for failure?",
      "answer": "Each step in a ReAct loop introduces a new point of failure. The model might: call the wrong tool, pass incorrect parameters, misinterpret tool output, enter an infinite loop, or take an irreversible action. With N steps, the probability of at least one error is 1 - (1-p)^N, where p is the per-step error rate. Even a 5% per-step error rate means a 40% chance of failure in a 10-step plan. This is why agentic workflows need robust error handling, step limits, and human oversight for consequential actions."
    },
    {
      "type": "markdown",
      "content": "## Tool Use\n\nModern AI APIs provide native support for tool use (also called \"function calling\"):\n\n```typescript\n// Define tools the model can use\nconst tools = [\n  {\n    name: \"get_weather\",\n    description: \"Get current weather for a location\",\n    parameters: {\n      type: \"object\",\n      properties: {\n        location: { type: \"string\", description: \"City name\" },\n        unit: { type: \"string\", enum: [\"celsius\", \"fahrenheit\"] },\n      },\n      required: [\"location\"],\n    },\n  },\n  {\n    name: \"search_web\",\n    description: \"Search the web for current information\",\n    parameters: {\n      type: \"object\",\n      properties: {\n        query: { type: \"string\" },\n      },\n      required: [\"query\"],\n    },\n  },\n];\n\n// Model decides when and how to use tools\nconst response = await anthropic.messages.create({\n  model: \"claude-sonnet-4-5-20250929\",\n  messages: [{ role: \"user\", content: \"What's the weather in Tokyo?\" }],\n  tools: tools,\n});\n// Response includes a tool_use block with name=\"get_weather\" and input={location: \"Tokyo\"}\n```\n\nThe model does not execute the tools -- it produces a structured request specifying which tool to call and with what parameters. Your code executes the tool and feeds the result back.\n\n## Multi-Agent Systems\n\nFor complex tasks, multiple specialized agents can collaborate:\n\n### Orchestration Patterns\n\n**Sequential Pipeline**: Each agent handles one stage, passing results to the next.\n```\nResearch Agent \u2500\u2500> Writing Agent \u2500\u2500> Review Agent \u2500\u2500> Final Output\n```\n\n**Supervisor Pattern**: A central agent delegates tasks and synthesizes results.\n```\n              \u250c\u2500\u2500 Research Agent\nSupervisor \u2500\u2500\u2500\u253c\u2500\u2500 Analysis Agent\n              \u2514\u2500\u2500 Writing Agent\n```\n\n**Debate / Adversarial**: Agents argue different positions, improving through disagreement.\n```\nProposer Agent \u2500\u2500> Critic Agent \u2500\u2500> Proposer refines \u2500\u2500> ... \u2500\u2500> Consensus\n```\n\n### Multi-Agent vs. Multi-Model\n\nIt is important to distinguish **multi-agent systems** from **multi-model architectures**. Multi-agent systems (covered in depth in module 5.8) involve multiple agent *instances* -- possibly running the same or different models -- coordinating on shared tasks through message passing, task delegation, and team protocols. The focus is on collaboration, task decomposition, and coordination overhead. Multi-model architectures (covered in module 5.12) assign different *model types* to different system roles -- a small fast model as a router, a large model for complex reasoning, a fine-tuned model for domain tasks, and a separate evaluator for quality checks. The focus is on cost optimization, latency management, and separation of concerns at the model selection level. Many production systems combine both: a multi-agent team where each agent uses a multi-model pipeline internally."
    },
    {
      "type": "tryItYourself",
      "title": "Design a multi-agent system for automated code review. Define at least three specialized agents, their tools, and how they coordinate. Consider: What does each agent focus on? How do they share findings? Who makes the final decision?",
      "solution": "**Agent 1: Security Reviewer**\n- Focus: Vulnerabilities, injection risks, authentication issues\n- Tools: `run_sast_scanner`, `check_dependency_vulnerabilities`, `search_cve_database`\n- Output: List of security findings with severity ratings\n\n**Agent 2: Style & Standards Reviewer**\n- Focus: Code style, naming conventions, architectural patterns\n- Tools: `run_linter`, `check_test_coverage`, `compare_to_style_guide`\n- Output: Style violations and improvement suggestions\n\n**Agent 3: Logic Reviewer**\n- Focus: Correctness, edge cases, performance\n- Tools: `run_tests`, `analyze_complexity`, `check_error_handling`\n- Output: Logic issues and potential bugs\n\n**Supervisor Agent**:\n- Receives findings from all three agents\n- Deduplicates and prioritizes issues\n- Produces a unified review with the most critical items first\n- Has the tool `post_review_comment` to write the final GitHub review\n\nCoordination: Supervisor dispatches the code diff to all three agents in parallel, collects their reports, then synthesizes a final review. If any agent reports a critical security issue, the supervisor automatically requests changes rather than approving."
    },
    {
      "type": "markdown",
      "content": "## Guardrails and Safety\n\nAgentic systems require additional safety measures:\n\n1. **Action boundaries**: Define what the agent is and is not allowed to do. Separate read-only tools from write tools.\n2. **Human-in-the-loop**: Require human approval for irreversible or high-impact actions (sending emails, making purchases, deleting data).\n3. **Step limits**: Cap the maximum number of reasoning steps to prevent runaway loops.\n4. **Cost limits**: Set per-task token budgets to prevent expensive reasoning spirals.\n5. **Output filtering**: Validate agent outputs before they reach external systems.\n\n```typescript\ninterface AgentPolicy {\n  maxSteps: number;\n  maxTokenBudget: number;\n  allowedTools: string[];\n  requireApproval: string[];  // tools needing human sign-off\n  forbiddenActions: string[];\n}\n```"
    },
    {
      "type": "providerContent",
      "providers": {
        "claude-code": "### Agentic Loops in Claude Code\n\nClaude Code demonstrates a mature agentic loop architecture with a rich tool set:\n\n**Tool Set**: Read, Write, Edit, Glob, Grep, Bash, WebFetch, and more. Each tool is purpose-built -- Read for files (not `cat`), Edit for surgical changes (not `sed`), Grep for content search (not `rg` via shell). This separation gives the agent precise, auditable actions rather than general-purpose shell access.\n\n**Permission Model**: Three tiers control agent autonomy:\n- **Default mode**: The agent proposes tool calls and the user approves or denies each one. This is human-in-the-loop at the tool level.\n- **acceptEdits mode**: File edits are auto-approved, but shell commands still require approval. Good for trusted coding tasks.\n- **bypassPermissions mode**: Full autonomy. The agent executes all tools without asking. Used in CI/CD pipelines or when the user explicitly trusts the agent.\n\n**Plan Mode**: Before executing, the agent can enter a plan-only mode where it reasons about the approach without taking actions. The plan must be approved before the agent switches to execution. This is a structured version of the ReAct \"Thought\" step.\n\n**Guardrails in Practice**: Step limits prevent runaway loops. The agent avoids destructive actions (force push, `rm -rf`) unless explicitly instructed. It checks for security vulnerabilities in generated code. Cost is managed through context compression when approaching token limits.",
        "codex": "### Agentic Loops in Codex (OpenAI)\n\nCodex uses a **sandboxed execution model** for agent safety. Each task runs in an isolated environment where the agent can read and write files, execute code, and run tests -- but cannot access the network or affect systems outside the sandbox. This is a hard boundary rather than a permission prompt.\n\n**File Access Patterns**: The agent reads the full repository into its context, makes changes, and runs verification commands (tests, linters) within the sandbox. Results are presented as a proposed diff that the user reviews and merges.\n\nThe sandbox model trades flexibility for safety: you cannot use Codex to call external APIs or deploy code, but you also cannot accidentally break production.",
        "cline": "### Agentic Loops in Cline\n\nCline integrates the agentic loop directly into VS Code:\n\n**VS Code Tool Integration**: Cline can read and write files, run terminal commands, control the browser, and interact with VS Code APIs (open files, navigate to symbols, run extensions). The editor itself becomes the tool environment.\n\n**MCP Tool Use**: Cline supports the Model Context Protocol (MCP), allowing it to connect to external tool servers. This means Cline's tool set is extensible -- you can add custom tools for database access, API calls, or domain-specific operations without modifying Cline itself.\n\n**Approval Workflows**: Cline shows each proposed action (file edit, command execution) and waits for user approval. An auto-approve mode allows the agent to proceed without interruption, similar to Claude Code's permission tiers. The user can configure which categories of actions require approval.",
        "gemini": "### Agentic Loops in Gemini / Jules\n\nGoogle's agentic coding tool **Jules** operates as an asynchronous agent. You assign it a GitHub issue, and it works independently on a branch -- planning, coding, testing, and submitting a pull request.\n\n**Agentic Capabilities**: Jules can analyze codebases, create multi-file changes, run tests, and iterate on failures. It works asynchronously, meaning you do not watch it execute step by step. Instead, you review the finished result.\n\n**Google Cloud Tool Integrations**: Gemini models in Google Cloud can access tools like Google Search grounding, code execution, and Vertex AI extensions. The Gemini API supports native function calling with automatic tool dispatch, and the Agent Development Kit (ADK) provides a framework for building custom agentic workflows with tool orchestration."
      }
    },
    {
      "type": "explainBack",
      "prompt": "Explain the ReAct framework and why it is more reliable than asking a model to answer complex questions from memory alone. Include the reasoning-acting-observing loop in your explanation."
    },
    {
      "type": "markdown",
      "content": "## From Theory to Practice\n\nThis module covered the theory of agentic workflows: ReAct loops, tool use, multi-agent patterns, and safety guardrails. The next four modules take you from theory to hands-on practice with the tools and protocols that make real-world agentic systems work:\n\n- **Module 5.6 -- Tool Protocols and MCP**: The standardized protocol that gives agents extensible, interoperable tool access\n- **Module 5.7 -- Subagents and Delegation**: How agents spawn child agents for parallel and specialized subtasks\n- **Module 5.8 -- Multi-Agent Teams**: Coordinating multiple agents on shared work with task systems, messaging, and shutdown protocols\n- **Module 5.9 -- Agent SDKs and Runtimes**: The developer kits that package all of these capabilities into buildable systems\n\nThese modules bridge the conceptual patterns introduced here with the concrete implementations you will use to build agentic applications."
    },
    {
      "type": "keyTakeaway",
      "content": "Agentic workflows give AI the ability to reason, use tools, and take multi-step actions autonomously. The ReAct framework interleaves thinking and tool use for grounded responses. Multi-agent systems let specialized agents collaborate on complex tasks. But agency comes with compounding error risk, making guardrails, step limits, and human oversight essential for production safety."
    },
    {
      "type": "connectPrompt",
      "prompt": "Module 5.6 introduces the Model Context Protocol (MCP) -- a standardized way for agents to discover and use tools. How does a universal tool protocol change the agentic patterns covered in this module? What becomes possible when any agent can connect to any tool server without custom integration code?"
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "Where is the line between 'useful automation' and 'risky autonomy' in your work context?",
        "How would you test an agentic workflow where the model's decisions change based on tool outputs?",
        "What governance and oversight structures should organizations put in place before deploying agentic AI?"
      ]
    }
  ]
}
