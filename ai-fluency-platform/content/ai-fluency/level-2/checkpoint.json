{
  "meta": {
    "title": "2.10 Level 2 Checkpoint",
    "description": "Test your prompt engineering skills. Apply zero-shot, few-shot, chain-of-thought, roles, and self-improvement techniques from memory.",
    "level": "level-2",
    "slug": "checkpoint",
    "order": 10,
    "isCheckpoint": true,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "markdown",
      "content": "## Checkpoint: The Prompt Engineer\n\nThis checkpoint tests whether you can deploy Level 2 techniques from memory. Do not scroll back to the modules. If a concept feels fuzzy, that is a signal to revisit the relevant module before moving to Level 3.\n\n### Concept recall"
    },
    {
      "type": "explainBack",
      "prompt": "Explain the difference between zero-shot and few-shot prompting. When would you use each? How many examples does few-shot typically need?"
    },
    {
      "type": "explainBack",
      "prompt": "What is chain-of-thought prompting? Why does it improve performance on multi-step problems? What is the simplest way to trigger it?"
    },
    {
      "type": "explainBack",
      "prompt": "How does role prompting work mechanically? What three elements should a good role prompt include? Does assigning a role give the model new knowledge?"
    },
    {
      "type": "explainBack",
      "prompt": "Name four parameters that control model output and explain what each one does. When would you use delimiters in a prompt, and what problem do they help prevent?"
    },
    {
      "type": "explainBack",
      "prompt": "Describe the recursive self-improvement loop. What is controlled hallucination and how does confidence tagging make it practical?"
    },
    {
      "type": "explainBack",
      "prompt": "What makes a prompt worth saving in a library? Explain prompt template variables and how they enable reuse. What are two platform-native tools for prompt persistence?"
    },
    {
      "type": "explainBack",
      "prompt": "Why would you run a model locally instead of using a cloud API? What is quantization and why is it necessary? When should you choose local over cloud inference?"
    },
    {
      "type": "explainBack",
      "prompt": "What three techniques make structured output requests (JSON, CSV) more reliable? Why is prompt-level structured output probabilistic rather than guaranteed?"
    },
    {
      "type": "explainBack",
      "prompt": "Describe the think-act-observe loop in agentic AI. What is tool calling, and who actually executes the tool -- the model or the surrounding system? Why does error propagation become a bigger concern in agentic systems?"
    },
    {
      "type": "markdown",
      "content": "### Applied exercises"
    },
    {
      "type": "tryItYourself",
      "title": "Design a few-shot prompt that teaches an AI to convert informal bug reports into structured tickets with fields: Severity (P1-P4), Component, Description, Steps to Reproduce. Write at least 3 examples and test with a new bug report.",
      "solution": "A strong answer includes 3+ examples with consistent formatting:\n\n```\nConvert bug reports to structured tickets.\n\nReport: \"App crashes whenever I try to upload a PDF larger than 10MB\"\nTicket:\n- Severity: P1\n- Component: File Upload\n- Description: Application crashes on PDF upload exceeding 10MB\n- Steps to Reproduce: 1. Navigate to upload page 2. Select PDF file >10MB 3. Click upload 4. Observe crash\n\nReport: \"The dark mode toggle doesn't change the sidebar color\"\nTicket:\n- Severity: P3\n- Component: UI/Theme\n- Description: Dark mode toggle fails to update sidebar styling\n- Steps to Reproduce: 1. Open settings 2. Toggle dark mode 3. Observe sidebar remains in light mode\n\nReport: \"Sometimes search results take 30+ seconds to load\"\nTicket:\n- Severity: P2\n- Component: Search\n- Description: Intermittent slow search performance exceeding 30 seconds\n- Steps to Reproduce: 1. Navigate to search 2. Enter query 3. Observe load time (intermittent)\n```\n\nKey elements: consistent field order, consistent severity calibration across examples, concise but complete descriptions."
    },
    {
      "type": "tryItYourself",
      "title": "You are building a prompt for a customer-facing chatbot that answers questions about your company's return policy. Write a complete system message that includes: a role, behavioral guidelines, scope boundaries, and a structured format for responses. Include a delimiter strategy for separating the policy document from the chat.",
      "solution": "A complete system message:\n\n```\nSystem: You are a helpful customer service agent for\n[Company]. You answer questions about our return policy\nwith a friendly, professional tone.\n\nBehavioral guidelines:\n- Always reference the specific policy section in your answer\n- If the customer's question is not covered by the policy, say \"I don't have information about that specific case. Let me connect you with a team member.\"\n- Never make up policy details that are not in the provided document\n- Keep answers under 3 sentences unless the customer asks for more detail\n\nScope boundaries:\n- Only answer questions about returns and refunds\n- Do not discuss pricing, shipping, or account issues\n- Do not offer discounts or make exceptions to policy\n\n<policy_document>\n[Full return policy text goes here]\n</policy_document>\n\nResponse format:\nAnswer: [Your response]\nPolicy Reference: [Section number or title]\n```\n\nKey elements: clear role, explicit behavioral rules, defined scope, delimiter-separated policy document, structured response format."
    },
    {
      "type": "tryItYourself",
      "title": "Take the following badly written prompt and improve it using at least three Level 2 techniques: 'Tell me about database optimization.' Your improved prompt should demonstrate few-shot, chain-of-thought, role assignment, or parameter awareness.",
      "solution": "An improved prompt combining multiple techniques:\n\n```\nYou are a senior database administrator with 15 years of\nexperience in PostgreSQL and MySQL. [ROLE]\n\nI need to optimize a slow query on a users table with\n10 million rows. The query filters by email and sorts\nby created_at.\n\nAnalyze this step by step: [CHAIN-OF-THOUGHT]\n1. Identify likely performance bottlenecks\n2. Suggest indexing strategies\n3. Recommend query restructuring if needed\n4. Estimate the performance improvement\n\nHere is an example of the analysis format I want: [FEW-SHOT]\n\nQuery: SELECT * FROM orders WHERE status = 'pending' ORDER BY date\nAnalysis:\n- Bottleneck: Full table scan on status column, filesort on date\n- Index: CREATE INDEX idx_status_date ON orders(status, date)\n- Restructure: Select only needed columns instead of *\n- Estimate: 10x improvement with composite index\n\nNow analyze:\nQuery: SELECT * FROM users WHERE email LIKE '%@gmail.com' ORDER BY created_at DESC\n```\n\nThis combines role assignment (senior DBA), chain-of-thought (step-by-step analysis), and few-shot (example of desired format). A parameter-aware note: this would work best at temperature 0.0-0.2 for technical accuracy."
    },
    {
      "type": "markdown",
      "content": "### Self-assessment\n\nRate your confidence on each Level 2 technique from 1 (cannot explain it) to 5 (could teach it):\n\n| Technique | Confidence (1-5) |\n| :-- | :-- |\n| Zero-shot vs. few-shot prompting | |\n| Chain-of-thought reasoning | |\n| Role and persona assignment | |\n| Temperature, top-p, max tokens, delimiters | |\n| Recursive self-improvement | |\n| Prompt libraries and optimization | |\n| Local models and privacy | |\n| Structured output formatting | |\n| Agentic loops and tool calling | |\n\nIf any technique is below a 3, revisit that module before continuing."
    },
    {
      "type": "keyTakeaway",
      "content": "Level 2 fluency means you can deliberately choose and combine prompting techniques to get reliable, high-quality output. You understand that few-shot teaches format, chain-of-thought enables reasoning, roles shape perspective, parameters control behavior, and self-critique refines quality. You also know how to build a reusable prompt library, when to run models locally for privacy, how to request structured output for automation, and how agentic loops extend AI beyond single-turn responses. If you can design prompts that combine multiple techniques for a specific task, you are ready for Level 3."
    }
  ]
}