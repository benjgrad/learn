{
  "meta": {
    "title": "2.3 Roles and Personas",
    "description": "Learn how assigning the model a specific identity shapes its tone, knowledge depth, and reasoning perspective.",
    "level": "level-2",
    "slug": "roles-and-personas",
    "order": 3,
    "isCheckpoint": false,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "predictPrompt",
      "prompt": "If you tell an AI 'You are an experienced tax accountant,' do you think the quality of its tax-related answers will change? What about the style and tone? Why would this work?"
    },
    {
      "type": "markdown",
      "content": "## Why roles work\n\nWhen you assign the model a role -- \"You are an expert software architect\" or \"Act as a senior data analyst\" -- you are manipulating the probability distribution over its output tokens. The model has been trained on text written by people in many roles and contexts. By specifying a role, you bias the model toward the vocabulary, reasoning patterns, and level of detail associated with that role in the training data.\n\nThis is not role-play for entertainment. It is a **prompt engineering technique** that:\n\n- Sets the expected **knowledge depth** (expert vs. beginner)\n- Shapes the **tone and style** (formal vs. casual, technical vs. accessible)\n- Activates relevant **domain vocabulary** and reasoning patterns\n- Establishes **perspective** (advisor, critic, teacher, interviewer)\n\n### System messages vs. inline roles\n\nThere are two ways to assign a role:\n\n**System message** (when using APIs or platforms that support it):\n```\nSystem: You are a senior backend engineer with 15 years\nof experience in distributed systems. You give direct,\ntechnical answers and flag potential scalability issues\nin any proposed solution.\n```\n\n**Inline role** (in any chat interface):\n```\nAct as a senior backend engineer with 15 years of\nexperience in distributed systems. Review the following\narchitecture proposal and identify scalability concerns.\n```\n\nSystem messages are processed differently by some models -- they may receive higher priority or persist across turns more reliably. But both approaches work by setting context that influences subsequent token predictions.\n\n### Crafting effective role prompts\n\nA good role prompt includes:\n\n1. **Identity**: Who the model is (\"You are a...\")\n2. **Experience level**: How much expertise to assume (\"senior,\" \"10 years,\" \"world-class\")\n3. **Behavioral guidelines**: How to respond (\"be concise,\" \"ask clarifying questions first,\" \"always provide examples\")\n4. **Scope boundaries**: What to focus on and what to avoid (\"focus on Python solutions,\" \"do not suggest cloud services\")\n\n```\nYou are a technical writing editor with expertise in\ndeveloper documentation. Your job is to review text for\nclarity, accuracy, and consistency. When you find issues:\n- Quote the problematic text\n- Explain the issue in one sentence\n- Provide a corrected version\nDo not rewrite entire sections. Focus on specific fixes.\n```"
    },
    {
      "type": "calibrationCheck",
      "question": "Does assigning a role actually give the model new knowledge it did not have before?",
      "answer": "No. The model's weights are fixed. A role prompt does not add knowledge -- it shifts which existing patterns the model draws from. If the model was not trained on relevant data for a domain, no role prompt will create expertise that is not there. What role prompts do is help the model surface the most relevant subset of its existing knowledge and present it in an appropriate style."
    },
    {
      "type": "markdown",
      "content": "### Combining roles with other techniques\n\nRoles become especially powerful when combined with the techniques from earlier modules:\n\n**Role + few-shot**: Provide examples of how this role would respond\n```\nYou are a code reviewer. Here is how you give feedback:\n\nCode: `for i in range(len(items)):`\nFeedback: \"Use `for item in items:` instead of indexing.\nMore Pythonic and less error-prone.\"\n\nCode: `data = json.loads(open('file.json').read())`\nFeedback:\n```\n\n**Role + chain-of-thought**: Ask the persona to show its reasoning\n```\nYou are a financial analyst. Walk me through your\nanalysis step by step. For each step, state your\nassumption and your calculation.\n```"
    },
    {
      "type": "tryItYourself",
      "title": "Take a question you recently asked an AI chatbot. Ask it again three ways: (1) with no role, (2) as 'a beginner-friendly teacher,' and (3) as 'an expert speaking to peers.' Compare the vocabulary, depth, and tone of the three responses.",
      "solution": "You should see clear differences:\n- **No role**: The model guesses the appropriate level, often defaulting to a generic mid-level response\n- **Beginner teacher**: Simpler vocabulary, more analogies, more explanation of basic concepts, encouraging tone\n- **Expert to peers**: Technical jargon, assumes prior knowledge, more concise, may reference specific tools or methodologies\n\nThis demonstrates that the role prompt shifts which part of the training distribution the model draws from."
    },
    {
      "type": "markdown",
      "content": "### Common role patterns\n\n| Role | Use case |\n| :-- | :-- |\n| \"Expert in [domain]\" | Get deeper, more technical responses |\n| \"Devil's advocate\" | Stress-test ideas and find weaknesses |\n| \"ELI5 teacher\" | Simplify complex topics for non-experts |\n| \"Job interviewer for [role]\" | Practice interview questions |\n| \"Editor / proofreader\" | Get focused writing feedback |\n| \"Customer with [specific concern]\" | Test how your messaging lands |"
    },
    {
      "type": "providerContent",
      "context": "### Persistent Personas in Your Tool\n\nInstead of repeating role instructions every conversation, your tool can maintain persistent personas:",
      "providers": {
        "claude-code": "Claude Code uses **CLAUDE.md** files as persistent persona and role definitions. Place a CLAUDE.md file in your project's root directory with instructions like \"You are a senior backend engineer. Always consider error handling and edge cases. Prefer TypeScript over JavaScript. Follow our team's naming conventions.\" These instructions are automatically included in every Claude Code conversation within that project.\n\nCLAUDE.md supports a hierarchy: project-level files apply to everyone working on the repo, while user-level files in `~/.claude/CLAUDE.md` apply to all your projects. This means your team shares the same AI persona through version-controlled CLAUDE.md files, ensuring consistent behavior across developers. For one-off persona changes, you can also use the `--system-prompt` flag: `claude --system-prompt \"You are a security auditor. Focus on OWASP Top 10 vulnerabilities.\"` This overrides the default behavior for a single session without modifying your persistent configuration.",
        "codex": "Codex supports **system instructions** that persist across sessions. You can configure these in the settings panel, defining the role and behavioral guidelines that Codex should follow in every interaction. For example, setting the system instructions to \"You are a senior full-stack developer. Always write tests alongside implementation code. Prefer functional patterns over class-based patterns.\"\n\nFor team consistency, Codex supports **organization-level instructions** that apply to all members. This means an engineering lead can define a shared persona — coding standards, review criteria, documentation requirements — that every team member's Codex instance follows. This is the team prompt library concept from Module 2.6 built directly into the tool. Individual developers can still add their own instructions on top of the organization defaults.",
        "cline": "Cline provides a **custom instructions** field in the extension settings that applies to every conversation. This is where you define your persistent persona — coding style preferences, language choices, review criteria, or any behavioral guidelines. For example: \"You are a React specialist. Use functional components with hooks. Prefer Tailwind CSS for styling. Write unit tests with Vitest.\"\n\nCline also supports **project-specific instruction sets**, so you can define different personas for different codebases. Your open-source project might use one set of guidelines while your enterprise codebase uses another. When you switch workspaces in VS Code, Cline automatically loads the appropriate instructions. This means the role prompt follows the project, not the conversation — exactly the persistent persona pattern described in this module.",
        "gemini": "Gemini supports persistent personas through **system instructions** in the CLI configuration and through **Gems** in the Gemini web interface. System instructions are defined once and apply to all subsequent interactions, acting as a persistent role prompt.\n\nGems take this further by letting you create **named, saveable personas** that you can switch between. A \"Code Reviewer\" Gem might include detailed review criteria and your team's style guide, while a \"Technical Writer\" Gem focuses on documentation clarity and API reference standards. Gems persist across conversations and can be shared within Google Workspace organizations, making them a built-in team prompt library. In the Gemini CLI, system instructions serve the same purpose — define your preferred role and behavioral guidelines once, and they apply to every interaction."
      }
    },
    {
      "type": "explainBack",
      "prompt": "Explain how role prompting works mechanically -- what is it doing to the model's token predictions? Name three elements of a good role prompt. What can role prompting NOT do?"
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "Do you change how you communicate when talking to different audiences at work? Role prompting works on the same principle.",
        "What role would be most useful for your day-to-day work? Draft a system message for that role.",
        "When might a role prompt be misleading -- making the model sound more authoritative than its actual knowledge justifies?"
      ]
    },
    {
      "type": "keyTakeaway",
      "content": "Role prompting biases the model's output toward specific vocabulary, reasoning patterns, and tone by shifting which training data patterns it draws from. It does not add new knowledge. Combine roles with few-shot examples and chain-of-thought for maximum control over output quality and style."
    },
    {
      "type": "connectPrompt",
      "prompt": "Roles control perspective and tone. In Module 2.4, you will learn how to control the model's behavior at a lower level through parameters like temperature, top-p, max tokens, and delimiters -- the knobs and switches beneath the surface."
    }
  ]
}