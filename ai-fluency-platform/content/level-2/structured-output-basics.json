{
  "meta": {
    "title": "2.8 Structured Output Basics",
    "description": "Learn to request JSON, CSV, and structured formats from AI models through prompt techniques.",
    "level": "level-2",
    "slug": "structured-output-basics",
    "order": 8,
    "isCheckpoint": false,
    "isIndex": false
  },
  "blocks": [
    {
      "type": "predictPrompt",
      "prompt": "If you ask an AI to 'give me the data as JSON,' do you think it will always produce valid, parseable JSON? What could go wrong?"
    },
    {
      "type": "markdown",
      "content": "## Why structured output matters\n\nMost AI interactions produce free-form text. That is fine for reading, but useless for automation. If you want to feed AI output into a spreadsheet, a database, a script, or another tool, you need the output in a predictable, machine-readable format.\n\nStructured output is the bridge between conversational AI and practical workflows. Master it and you unlock the ability to chain AI into larger systems -- even without writing code.\n\n### The prompt-level approach\n\nThis module focuses on getting structured output through **prompting techniques alone**. You write your prompt in a way that makes the model produce formatted output. This approach is accessible to everyone, requires no programming, and works across all AI providers.\n\nIn Level 4, you will learn about **deterministic enforcement** -- API features like JSON mode and function calling that guarantee valid structure. For now, prompt-level techniques get you 90% of the way there.\n\n## Requesting JSON\n\nJSON (JavaScript Object Notation) is the most common structured format for data exchange. To get JSON output from a model, you need three things: an explicit format request, an example of the structure, and clear field definitions.\n\n### Basic JSON request\n\n```\nExtract the following information from this product review\nand return it as JSON:\n\n- sentiment (positive, negative, or mixed)\n- key_topics (array of main subjects discussed)\n- rating_mentioned (true/false)\n- summary (one sentence)\n\nReview: \"The laptop is incredibly fast and the screen is\ngorgeous, but the battery barely lasts 4 hours. For the\nprice, I expected better battery life. The keyboard is\ndecent. 3 out of 5 stars.\"\n```\n\nThe model will typically produce something like:\n\n```json\n{\n  \"sentiment\": \"mixed\",\n  \"key_topics\": [\"performance\", \"display\", \"battery life\", \"keyboard\", \"price\"],\n  \"rating_mentioned\": true,\n  \"summary\": \"Fast laptop with great screen but disappointing battery life for the price.\"\n}\n```\n\n### Providing a schema example\n\nFor complex structures, show the model exactly what you want:\n\n```\nConvert each employee record to JSON matching this schema:\n\n{\n  \"name\": \"string\",\n  \"department\": \"string\",\n  \"skills\": [\"string\"],\n  \"years_experience\": number,\n  \"is_manager\": boolean\n}\n\nRecords:\n- Jane Chen, Engineering, Python/Go/Kubernetes, 8 years, manages a team of 5\n- Marcus Webb, Marketing, SEO/Analytics/Content Strategy, 3 years, individual contributor\n```\n\nProviding the schema as an example is a form of few-shot prompting applied to structure. The model matches the pattern you demonstrate.\n\n## Requesting CSV\n\nCSV (comma-separated values) is ideal when you want to paste output directly into a spreadsheet.\n\n```\nAnalyze the following sales data and return a CSV with\ncolumns: Month, Revenue, Growth_Percent, Top_Product\n\nData: In January we made $45K mainly from Widget A.\nFebruary jumped to $52K driven by Widget B. March\ndropped to $38K, mostly Widget A again.\n```\n\nExpected output:\n\n```csv\nMonth,Revenue,Growth_Percent,Top_Product\nJanuary,45000,,Widget A\nFebruary,52000,15.6,Widget B\nMarch,38000,-26.9,Widget A\n```\n\n### CSV tips\n\n- Ask the model to use a **header row** explicitly -- some models omit it\n- Specify how to handle **missing values** (empty field, \"N/A\", or 0)\n- For data containing commas, request that the model **quote fields** appropriately\n\n## Requesting markdown tables\n\nMarkdown tables are useful when you want structured output that is also human-readable:\n\n```\nCompare these three programming languages for web\ndevelopment. Return a markdown table with columns:\nLanguage, Learning Curve, Performance, Ecosystem,\nBest For.\n\nLanguages: Python, JavaScript, Go\n```\n\nMarkdown tables render nicely in most chat interfaces and can be pasted directly into documentation.\n\n## Techniques for reliable structure\n\n### Technique 1: Explicit format instruction\n\nAlways state the format explicitly. Do not rely on the model to guess:\n\n```\nReturn your answer as valid JSON. Do not include any\ntext before or after the JSON object.\n```\n\nThe instruction \"do not include any text before or after\" prevents the model from adding conversational preamble like \"Here is the JSON:\" which breaks parsing.\n\n### Technique 2: Show, do not tell\n\nCombine a structural instruction with a concrete example. The model follows demonstrated patterns more reliably than described ones.\n\n### Technique 3: Constrain the fields\n\nDefine every field the model should include. Open-ended requests like \"return relevant information as JSON\" produce inconsistent schemas across runs.\n\n### Technique 4: Handle edge cases in the prompt\n\nTell the model what to do when data is missing, ambiguous, or does not fit the schema:\n\n```\nIf a field cannot be determined from the input, use null.\nIf a field could have multiple values, use an array.\nDo not invent data that is not present in the source text.\n```"
    },
    {
      "type": "providerContent",
      "context": "### Structured Output in Your Tool\n\nEach tool handles structured output differently at the API level:",
      "providers": {
        "claude-code": "Claude Code supports structured output through **tool use** — you define a tool with a JSON schema, and Claude returns data matching that schema exactly. In the API, this provides reliable structured output because the model's response is constrained to valid tool-call arguments. Claude also supports a **JSON mode** that forces the response to be valid JSON.\n\nIn the CLI, Claude naturally produces structured output when asked. A prompt like `claude --print \"list the exported functions in src/utils.ts as a JSON array with name and line number\"` will produce clean JSON output that you can pipe into other tools: `claude --print \"...\" | jq '.[] | .name'`. The `--print` flag is especially useful here because it outputs only the response text without the interactive UI, making it easy to integrate Claude's structured output into shell scripts and automation pipelines.",
        "codex": "Codex offers the most robust structured output guarantees through OpenAI's **Structured Outputs** feature. When you provide a JSON schema, the API guarantees that the response will be valid JSON matching your schema exactly — no trailing commas, no missing fields, no extra text. This is deterministic enforcement, not probabilistic prompting.\n\n**Function calling** provides another path to structured output: define functions with typed parameters, and the model returns arguments matching those types. This is the foundation of tool use in agentic systems. In the Codex CLI, you can request JSON output directly, and **JSON mode** ensures the response is always valid parseable JSON. For production systems where invalid JSON would cause failures, Codex's deterministic structured output is a significant advantage over prompt-level techniques alone.",
        "cline": "Structured output support in Cline depends on which model backend you have configured. If you are using **OpenAI-compatible endpoints**, you get access to JSON mode and function calling for guaranteed structured output. If you are using Claude models, tool use provides schema-constrained output.\n\nIn practice, Cline handles the parsing and display of structured output in the VS Code UI. When Claude or GPT returns JSON, Cline can format it readably in the chat panel. For code generation tasks, structured output is less relevant because Cline writes directly to your files — the \"structure\" is the code itself. Where structured output matters most in Cline is when you are extracting data from codebases (listing endpoints, cataloging dependencies, mapping file relationships) and want the results in a format you can process further.",
        "gemini": "Gemini supports structured output through **JSON mode** and a **response schema** parameter in the API. JSON mode ensures the model returns valid JSON, while the response schema parameter lets you define the exact structure — field names, types, nesting — that the response must match. This provides deterministic enforcement similar to OpenAI's Structured Outputs.\n\nA unique strength of Gemini's structured output is that it works with **multimodal inputs**. You can pass an image and a JSON schema, and Gemini will extract structured data from the image in the format you specified. For example, extracting product information from a screenshot into a typed JSON object. In the Gemini CLI, requesting structured output follows the same prompt techniques covered in this module, with the added confidence that API-level schema enforcement can guarantee validity when needed."
      }
    },
    {
      "type": "calibrationCheck",
      "question": "If you ask the model for JSON, will it always produce valid JSON?",
      "answer": "No. Prompt-level JSON requests are **probabilistic**, not guaranteed. The model might add explanatory text around the JSON, produce a trailing comma, miss a closing brace, or use single quotes instead of double quotes. For casual use, prompt techniques work well -- perhaps 90-95% of the time with a well-written prompt. For production systems where invalid JSON causes a crash, you need deterministic enforcement through API features like OpenAI's JSON mode or structured output schemas. You will learn those techniques in Level 4."
    },
    {
      "type": "markdown",
      "content": "## Common failure modes\n\n| Problem | Cause | Fix |\n| :-- | :-- | :-- |\n| JSON wrapped in markdown code fences | Model adds ` ```json ` formatting | Ask explicitly for raw JSON with no code fences |\n| Extra conversational text | Model adds \"Here is the JSON:\" preamble | Add \"Output only the JSON, nothing else\" |\n| Inconsistent field names | Ambiguous prompt | Provide an explicit schema example |\n| Nested structure is wrong | Complex schema described in prose | Show the exact nesting via example |\n| Truncated output | Response hit max token limit | Reduce the data scope or increase token limit |"
    },
    {
      "type": "tryItYourself",
      "title": "Take a paragraph of unstructured text (a product review, a meeting summary, or a news article) and write a prompt that extracts key information into JSON. Run it three times and check whether the JSON is valid and consistent across runs. Note any variations in structure or content.",
      "solution": "Across three runs, you will likely see the same overall structure but minor variations: field ordering may change, array items may appear in different order, and wording of string values will differ. If the structure itself varies (different field names, missing fields), your prompt needs a more explicit schema definition. Try adding an example of the exact output structure you want."
    },
    {
      "type": "explainBack",
      "prompt": "Explain why structured output matters for automation. What three techniques make JSON requests more reliable? Why can you not guarantee valid JSON through prompting alone, and what is the alternative?"
    },
    {
      "type": "reflectPrompt",
      "questions": [
        "What tasks in your current workflow involve manually reformatting AI output? Could structured output prompts eliminate that step?",
        "When would you choose CSV over JSON, or a markdown table over either?",
        "How comfortable are you with the idea that prompt-level structured output is probabilistic rather than guaranteed?"
      ]
    },
    {
      "type": "keyTakeaway",
      "content": "Structured output -- JSON, CSV, markdown tables -- bridges the gap between conversational AI and automated workflows. Prompt-level techniques (explicit format instructions, schema examples, field constraints, and edge case handling) produce reliable structure most of the time. For guaranteed valid output in production systems, you will need the deterministic API features covered in Level 4. Start with prompt techniques to build intuition for what works."
    },
    {
      "type": "connectPrompt",
      "prompt": "Structured output lets you feed AI results into other tools. But what if the AI could use those tools directly? In Module 2.9, you will learn about agentic loops -- the pattern that lets AI models take actions, observe results, and reason about what to do next."
    }
  ]
}