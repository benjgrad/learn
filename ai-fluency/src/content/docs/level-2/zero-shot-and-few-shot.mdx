---
title: "2.1 Zero-Shot and Few-Shot Prompting"
description: "Learn how providing examples in your prompt teaches the model to follow patterns it was never explicitly trained on."
sidebar:
  order: 1
---

import PredictPrompt from '../../../components/learning/PredictPrompt.astro';
import TryItYourself from '../../../components/learning/TryItYourself.astro';
import CalibrationCheck from '../../../components/learning/CalibrationCheck.astro';
import ExplainBack from '../../../components/learning/ExplainBack.astro';
import ReflectPrompt from '../../../components/learning/ReflectPrompt.astro';
import ConnectPrompt from '../../../components/learning/ConnectPrompt.astro';
import KeyTakeaway from '../../../components/learning/KeyTakeaway.astro';

<PredictPrompt prompt="If you wanted an AI to format text in a very specific way that it has never seen before -- say, your company's internal notation style -- how would you get it to do that without retraining the model?" />

## Zero-shot: instructions only

Every prompt you wrote in Level 1 was a **zero-shot** prompt: you gave the model an instruction and zero examples of the desired output. The model relied entirely on its pre-trained knowledge to interpret your request.

```
Classify the following customer message as "billing",
"technical", or "general":

"I can't log into my account after changing my password."
```

Zero-shot works well when the task is common (classification, summarization, translation) and the expected output format is standard. The model has seen millions of similar tasks during training and can generalize.

But zero-shot fails when:
- Your desired output format is unusual or proprietary
- The task requires a specific reasoning pattern the model does not default to
- You need consistent formatting across many outputs

## Few-shot: teaching by example

**Few-shot prompting** (also called **in-context learning**) adds examples of input-output pairs before the actual task. The model detects the pattern in your examples and applies it to the new input.

```
Classify customer messages. Here are examples:

Message: "When is my next invoice due?"
Category: billing

Message: "The dashboard is loading slowly."
Category: technical

Message: "Do you have a referral program?"
Category: general

Message: "I can't log into my account after changing my password."
Category:
```

The model sees the pattern (message followed by category) and continues it. This is remarkably powerful because you are effectively **programming the model through examples** without writing code or retraining anything.

<CalibrationCheck question="How many examples do you typically need for few-shot prompting to work? Is there a minimum or maximum?">
There is no hard minimum, but research shows:
- **1-shot** (one example) often provides a significant improvement over zero-shot for formatting tasks
- **3-5 examples** typically establish a robust pattern for most tasks
- Beyond **10-15 examples**, you get diminishing returns and risk filling up the context window

The quality and diversity of examples matters more than quantity. Choose examples that cover the range of cases the model will encounter.
</CalibrationCheck>

### Why few-shot works

Few-shot learning is an **emergent property** of large language models -- it was not explicitly programmed. It emerges because the model was trained on text that naturally contains patterns and continuations. When you provide examples, you are creating a pattern within the context window, and the model continues that pattern.

This means few-shot learning is actually a form of the same next-token prediction you learned about in Level 1. The model is not "learning" from your examples in any deep sense -- it is recognizing a pattern and predicting what comes next.

### Designing effective examples

Good few-shot examples share several properties:

1. **Representative**: Cover the range of inputs the model will see
2. **Consistent**: Use identical formatting across all examples
3. **Clear boundaries**: Use markers to separate input from output
4. **Ordered thoughtfully**: Place the most representative examples first

Bad examples can actively hurt performance. If your examples contain inconsistencies or errors, the model will learn those inconsistencies.

<TryItYourself title="Create a few-shot prompt that teaches an AI to convert informal meeting notes into structured action items with an owner, deadline, and description. Write 3 examples, then test with a real set of meeting notes.">
A well-structured few-shot prompt might look like:

```
Convert meeting notes into structured action items.

Notes: "John will handle the API docs by Friday. Sarah needs to review the test coverage."
Action items:
- Owner: John | Deadline: Friday | Task: Write API documentation
- Owner: Sarah | Deadline: TBD | Task: Review test coverage

Notes: "We need someone to set up monitoring. Mark volunteered, aiming for end of sprint."
Action items:
- Owner: Mark | Deadline: End of sprint | Task: Set up monitoring system

Notes: [your actual meeting notes here]
Action items:
```

The key is consistent formatting across examples: same delimiter (|), same field order (Owner, Deadline, Task), same handling of missing information (TBD).
</TryItYourself>

### Zero-shot vs. few-shot: when to use which

| Situation | Recommended approach |
| :-- | :-- |
| Standard task (summarize, translate) | Zero-shot is usually sufficient |
| Custom output format | Few-shot with 3-5 examples |
| Domain-specific classification | Few-shot with representative categories |
| Complex reasoning | Few-shot combined with chain-of-thought (Module 2.2) |
| Limited context window | Zero-shot to save tokens |

<ExplainBack prompt="Explain the difference between zero-shot and few-shot prompting. Why does few-shot work even though the model is not actually learning from your examples? When would you choose each approach?" />

<ReflectPrompt questions={[
  "Think of a task at work where the output format is specific to your organization. Could few-shot prompting handle it?",
  "What would happen if you provided contradictory examples in a few-shot prompt?",
  "How does the concept of in-context learning connect to the idea that AI is a next-token predictor?"
]} />

<KeyTakeaway>
Few-shot prompting teaches the model your desired pattern through examples placed directly in the prompt. It works because the model recognizes and continues patterns -- the same next-token prediction from Level 1, applied to your examples. Use 3-5 consistent, representative examples for best results.
</KeyTakeaway>

<ConnectPrompt prompt="Few-shot prompting controls the model's output format. In Module 2.2, you will learn chain-of-thought prompting, which controls the model's reasoning process -- forcing it to show its work step by step." />
